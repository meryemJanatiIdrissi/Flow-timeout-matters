{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor  \n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(predictions, targets, timeout, save_path= \"results/ET\"):\n",
    "    name_file_pred = 'predictions_idle_' + str(timeout[0]) + \"_active_\" + str(timeout[1]) + \".p\"\n",
    "    name_file_y = 'targets_idle_' + str(timeout[0]) + \"_active_\" + str(timeout[1]) + \".p\"\n",
    "\n",
    "    pickle.dump(predictions, open(os.path.join(save_path, name_file_pred), 'wb') )\n",
    "    pickle.dump(targets, open(os.path.join(save_path, name_file_y), 'wb') )\n",
    "    \n",
    "def load_predictions(timeout, save_path= \"results/ET\"):\n",
    "    name_file_pred = 'predictions_idle_' + str(timeout[0]) + \"_active_\" + str(timeout[1]) + \".p\"\n",
    "    name_file_y = 'targets_idle_' + str(timeout[0]) + \"_active_\" + str(timeout[1]) + \".p\"\n",
    "    \n",
    "    predictions =  pickle.load(open(os.path.join(save_path, name_file_pred), 'rb') )\n",
    "    targets =  pickle.load(open(os.path.join(save_path, name_file_y), 'rb') )\n",
    "    return predictions, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeouts = [(0.5,2), (1, 2), (2,2), (0.5,3), (1,3), (2, 3), (3,3), (0.5,4), (1, 4), (2,4), (3,4), (4,4), (0.5,5), (1,5), (2,5), (3,5), (4,5), (5,5), (0.5, 30), (1, 30), (2,30), (3,30), (4,30), (5,30), (10, 30), (0.5, 60), (1, 60), (2,60), (3,60), (4,60), (5,60), (10, 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load predictions - ET-BaslineFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading timeout :  (0.5, 2)\n",
      "Loading timeout :  (1, 2)\n",
      "Loading timeout :  (2, 2)\n",
      "Loading timeout :  (0.5, 3)\n",
      "Loading timeout :  (1, 3)\n",
      "Loading timeout :  (2, 3)\n",
      "Loading timeout :  (3, 3)\n",
      "Loading timeout :  (0.5, 4)\n",
      "Loading timeout :  (1, 4)\n",
      "Loading timeout :  (2, 4)\n",
      "Loading timeout :  (3, 4)\n",
      "Loading timeout :  (4, 4)\n",
      "Loading timeout :  (0.5, 5)\n",
      "Loading timeout :  (1, 5)\n",
      "Loading timeout :  (2, 5)\n",
      "Loading timeout :  (3, 5)\n",
      "Loading timeout :  (4, 5)\n",
      "Loading timeout :  (5, 5)\n",
      "Loading timeout :  (0.5, 30)\n",
      "Loading timeout :  (1, 30)\n",
      "Loading timeout :  (2, 30)\n",
      "Loading timeout :  (3, 30)\n",
      "Loading timeout :  (4, 30)\n",
      "Loading timeout :  (5, 30)\n",
      "Loading timeout :  (10, 30)\n",
      "Loading timeout :  (0.5, 60)\n",
      "Loading timeout :  (1, 60)\n",
      "Loading timeout :  (2, 60)\n",
      "Loading timeout :  (3, 60)\n",
      "Loading timeout :  (4, 60)\n",
      "Loading timeout :  (5, 60)\n",
      "Loading timeout :  (10, 60)\n",
      "------------------- DONE -------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, auc, roc_curve\n",
    "\n",
    "results = {}\n",
    "\n",
    "classes = ['Benign', 'Botnet', 'DDoS', 'DoS GoldenEye', 'DoS Hulk', 'DoS Slowhttptest', 'DoS Slowloris', 'FTP-Patator', 'Infiltration', 'Infiltration - Portscan',\n",
    " 'Portscan', 'SSH-Patator', 'Web Attack - Brute Force', 'Web Attack - SQL Injection', 'Web Attack - XSS']\n",
    "for timeout in timeouts:\n",
    "    print(\"Loading timeout : \", timeout)\n",
    "    idle, active = timeout\n",
    "    pred, y_test = load_predictions(timeout, save_path= \"../results/ET\")\n",
    "    report = classification_report(y_test, pred,  target_names=classes, digits=4)\n",
    "    f1 = f1_score(y_true=y_test, y_pred=pred, average='macro')\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred, average='macro')\n",
    "    recall = recall_score(y_test, pred, average='macro')\n",
    "    \n",
    "    results[str(timeout)] = [f1, accuracy, precision, recall]\n",
    "    \n",
    "    \n",
    "dictResults = sorted(results.items(), key=lambda x: x[1])\n",
    "df = pd.DataFrame(dictResults)\n",
    "\n",
    "df.to_excel('cic17_ET_baselineFeatures.xlsx')\n",
    "print(\"------------------- DONE -------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load predictions - RF-BaslineFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading timeout :  (0.5, 2)\n",
      "Loading timeout :  (1, 2)\n",
      "Loading timeout :  (2, 2)\n",
      "Loading timeout :  (0.5, 3)\n",
      "Loading timeout :  (1, 3)\n",
      "Loading timeout :  (2, 3)\n",
      "Loading timeout :  (3, 3)\n",
      "Loading timeout :  (0.5, 4)\n",
      "Loading timeout :  (1, 4)\n",
      "Loading timeout :  (2, 4)\n",
      "Loading timeout :  (3, 4)\n",
      "Loading timeout :  (4, 4)\n",
      "Loading timeout :  (0.5, 5)\n",
      "Loading timeout :  (1, 5)\n",
      "Loading timeout :  (2, 5)\n",
      "Loading timeout :  (3, 5)\n",
      "Loading timeout :  (4, 5)\n",
      "Loading timeout :  (5, 5)\n",
      "Loading timeout :  (0.5, 30)\n",
      "Loading timeout :  (1, 30)\n",
      "Loading timeout :  (2, 30)\n",
      "Loading timeout :  (3, 30)\n",
      "Loading timeout :  (4, 30)\n",
      "Loading timeout :  (5, 30)\n",
      "Loading timeout :  (10, 30)\n",
      "Loading timeout :  (0.5, 60)\n",
      "Loading timeout :  (1, 60)\n",
      "Loading timeout :  (2, 60)\n",
      "Loading timeout :  (3, 60)\n",
      "Loading timeout :  (4, 60)\n",
      "Loading timeout :  (5, 60)\n",
      "Loading timeout :  (10, 60)\n",
      "------------------- DONE -------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, auc, roc_curve\n",
    "\n",
    "results = {}\n",
    "\n",
    "classes = ['Benign', 'Botnet', 'DDoS', 'DoS GoldenEye', 'DoS Hulk', 'DoS Slowhttptest', 'DoS Slowloris', 'FTP-Patator', 'Infiltration', 'Infiltration - Portscan',\n",
    " 'Portscan', 'SSH-Patator', 'Web Attack - Brute Force', 'Web Attack - SQL Injection', 'Web Attack - XSS']\n",
    "for timeout in timeouts:\n",
    "    print(\"Loading timeout : \", timeout)\n",
    "    idle, active = timeout\n",
    "    pred, y_test = load_predictions(timeout, save_path= \"../results/RF\")\n",
    "    report = classification_report(y_test, pred,  target_names=classes, digits=4)\n",
    "    f1 = f1_score(y_true=y_test, y_pred=pred, average='macro')\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred, average='macro')\n",
    "    recall = recall_score(y_test, pred, average='macro')\n",
    "    \n",
    "    results[str(timeout)] = [f1, accuracy, precision, recall]\n",
    "    \n",
    "    \n",
    "dictResults = sorted(results.items(), key=lambda x: x[1])\n",
    "df = pd.DataFrame(dictResults)\n",
    "\n",
    "df.to_excel('cic17_RF_baselineFeatures.xlsx')\n",
    "print(\"------------------- DONE -------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load predictions - MLP-BaslineFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading timeout :  (0.5, 2)\n",
      "Loading timeout :  (1, 2)\n",
      "Loading timeout :  (2, 2)\n",
      "Loading timeout :  (0.5, 3)\n",
      "Loading timeout :  (1, 3)\n",
      "Loading timeout :  (2, 3)\n",
      "Loading timeout :  (3, 3)\n",
      "Loading timeout :  (0.5, 4)\n",
      "Loading timeout :  (1, 4)\n",
      "Loading timeout :  (2, 4)\n",
      "Loading timeout :  (3, 4)\n",
      "Loading timeout :  (4, 4)\n",
      "Loading timeout :  (0.5, 5)\n",
      "Loading timeout :  (1, 5)\n",
      "Loading timeout :  (2, 5)\n",
      "Loading timeout :  (3, 5)\n",
      "Loading timeout :  (4, 5)\n",
      "Loading timeout :  (5, 5)\n",
      "Loading timeout :  (0.5, 30)\n",
      "Loading timeout :  (1, 30)\n",
      "Loading timeout :  (2, 30)\n",
      "Loading timeout :  (3, 30)\n",
      "Loading timeout :  (4, 30)\n",
      "Loading timeout :  (5, 30)\n",
      "Loading timeout :  (10, 30)\n",
      "Loading timeout :  (0.5, 60)\n",
      "Loading timeout :  (1, 60)\n",
      "Loading timeout :  (2, 60)\n",
      "Loading timeout :  (3, 60)\n",
      "Loading timeout :  (4, 60)\n",
      "Loading timeout :  (5, 60)\n",
      "Loading timeout :  (10, 60)\n",
      "------------------- DONE -------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, auc, roc_curve\n",
    "\n",
    "results = {}\n",
    "\n",
    "classes = ['Benign', 'Botnet', 'DDoS', 'DoS GoldenEye', 'DoS Hulk', 'DoS Slowhttptest', 'DoS Slowloris', 'FTP-Patator', 'Infiltration', 'Infiltration - Portscan',\n",
    " 'Portscan', 'SSH-Patator', 'Web Attack - Brute Force', 'Web Attack - SQL Injection', 'Web Attack - XSS']\n",
    "for timeout in timeouts:\n",
    "    print(\"Loading timeout : \", timeout)\n",
    "    idle, active = timeout\n",
    "    pred, y_test = load_predictions(timeout, save_path= \"../results/MLP\")\n",
    "    report = classification_report(y_test, pred,  target_names=classes, digits=4)\n",
    "    f1 = f1_score(y_true=y_test, y_pred=pred, average='macro')\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred, average='macro')\n",
    "    recall = recall_score(y_test, pred, average='macro')\n",
    "    \n",
    "    results[str(timeout)] = [f1, accuracy, precision, recall]\n",
    "    \n",
    "    \n",
    "dictResults = sorted(results.items(), key=lambda x: x[1])\n",
    "df = pd.DataFrame(dictResults)\n",
    "\n",
    "df.to_excel('cic17_MLP_baselineFeatures.xlsx')\n",
    "print(\"------------------- DONE -------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ids_data",
   "language": "python",
   "name": "ids_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
