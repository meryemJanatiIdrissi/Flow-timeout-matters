{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_score(path):\n",
    "    with open(path, 'r') as f:\n",
    "        loaded_results = json.load(f)\n",
    "    return loaded_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ET = load_score('../results/basicFeatures/ET_unsw_nfstream.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_RF = load_score('../results/basicFeatures/RF_unsw_nfstream.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_MLP = load_score('../results/basicFeatures/MLP_unsw_nfstream.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ET classifier: \n",
      " {'Best score': {'Best Timeout': [4, 5], 'Mean Scores (Best)': {'f1Mean': 0.7248801803566035, 'accMean': 0.9881571398228015, 'recMean': 0.7133492132994818, 'precMean': 0.7684672278434999}, 'Std Scores (Best)': {'f1Std': 0.014988248665003857, 'accStd': 0.0025910006952542496, 'recStd': 0.007482423641287856, 'precStd': 0.062354879123533366}}, 'Worst score': {'Worst Timeout': [0.5, 60], 'Mean Scores (Worst)': {'f1Mean': 0.7175076194450114, 'accMean': 0.987919114896697, 'recMean': 0.7080174387824691, 'precMean': 0.7624302060549981}, 'Std Scores (Worst)': {'f1Std': 0.01802187260336165, 'accStd': 0.0026567002033118852, 'recStd': 0.0033690334837858747, 'precStd': 0.08118695578628274}}, 'Difference': {'Accuracy': 0.023802492610447423, 'F1 Score': 0.7372560911592108, 'Precision': 0.603702178850174, 'Recall': 0.5331774517012611}}\n",
      "\n",
      "RF classifier :\n",
      " {'Best score': {'Best Timeout': [2, 2], 'Mean Scores (Best)': {'f1Mean': 0.7197034319401785, 'accMean': 0.9883351548488418, 'recMean': 0.7083895689649256, 'precMean': 0.7730769897378899}, 'Std Scores (Best)': {'f1Std': 0.0177831461270605, 'accStd': 0.0024935776839261716, 'recStd': 0.007522545055841562, 'precStd': 0.08069174604705723}}, 'Worst score': {'Worst Timeout': [0.5, 3], 'Mean Scores (Worst)': {'f1Mean': 0.7149427942094987, 'accMean': 0.9881034171162018, 'recMean': 0.7015176718417777, 'precMean': 0.7674769896601521}, 'Std Scores (Worst)': {'f1Std': 0.01837623257999105, 'accStd': 0.0025360563028352908, 'recStd': 0.005511922067593151, 'precStd': 0.08350893227882218}}, 'Difference': {'Accuracy': 0.023173773264006936, 'F1 Score': 0.47606377306798064, 'Precision': 0.5600000077737755, 'Recall': 0.6871897123147841}}\n",
      "\n",
      "MLP classifier : \n",
      " {'Best score': {'Best Timeout': [0.5, 3], 'Mean Scores (Best)': {'f1Mean': 0.5385025982201224, 'accMean': 0.9854193579415126, 'recMean': 0.5305862878354152, 'precMean': 0.6060281025748958}, 'Std Scores (Best)': {'f1Std': 0.010739693831363853, 'accStd': 0.0024138502891582017, 'recStd': 0.01164069579366274, 'precStd': 0.0372076861655445}}, 'Worst score': {'Worst Timeout': [4, 60], 'Mean Scores (Worst)': {'f1Mean': 0.5114983481436209, 'accMean': 0.9857310347185922, 'recMean': 0.4961080679392261, 'precMean': 0.6287420530341901}, 'Std Scores (Worst)': {'f1Std': 0.010389177322929473, 'accStd': 0.0019387461669609822, 'recStd': 0.016661909039079607, 'precStd': 0.06827471398103704}}, 'Difference': {'Accuracy': -0.031167677707966135, 'F1 Score': 2.7004250076501424, 'Precision': -2.271395045929425, 'Recall': 3.4478219896189044}}\n"
     ]
    }
   ],
   "source": [
    "print(\"ET classifier: \\n\" , results_ET)\n",
    "print(\"\\nRF classifier :\\n\" , results_RF)\n",
    "print(\"\\nMLP classifier : \\n\" , results_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_ET_best = [0.7248801803566035, 0.014988248665003857]\n",
      "acc_ET_best = [0.9881571398228015, 0.0025910006952542496]\n",
      "rec_ET_best = [0.7133492132994818, 0.007482423641287856]\n",
      "prec_ET_best = [0.7684672278434999, 0.062354879123533366]\n",
      "f1_ET_worst = [0.7175076194450114, 0.01802187260336165]\n",
      "acc_ET_worst = [0.987919114896697, 0.0026567002033118852]\n",
      "rec_ET_worst = [0.7080174387824691, 0.0033690334837858747]\n",
      "prec_ET_worst = [0.7624302060549981, 0.08118695578628274]\n",
      "d_f1 = 0.7372560911592108\n",
      "d_acc = 0.023802492610447423\n",
      "d_rec = 0.5331774517012611\n",
      "d_prec = 0.603702178850174\n"
     ]
    }
   ],
   "source": [
    "et_classifier = results_ET\n",
    "\n",
    "# Best score variables\n",
    "f1_ET_best = [et_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"f1Mean\"], \n",
    "              et_classifier[\"Best score\"][\"Std Scores (Best)\"][\"f1Std\"]]\n",
    "acc_ET_best = [et_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"accMean\"], \n",
    "               et_classifier[\"Best score\"][\"Std Scores (Best)\"][\"accStd\"]]\n",
    "rec_ET_best = [et_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"recMean\"], \n",
    "               et_classifier[\"Best score\"][\"Std Scores (Best)\"][\"recStd\"]]\n",
    "prec_ET_best = [et_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"precMean\"], \n",
    "                et_classifier[\"Best score\"][\"Std Scores (Best)\"][\"precStd\"]]\n",
    "\n",
    "# Worst score variables\n",
    "f1_ET_worst = [et_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"f1Mean\"], \n",
    "               et_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"f1Std\"]]\n",
    "acc_ET_worst = [et_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"accMean\"], \n",
    "                et_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"accStd\"]]\n",
    "rec_ET_worst = [et_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"recMean\"], \n",
    "                et_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"recStd\"]]\n",
    "prec_ET_worst = [et_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"precMean\"], \n",
    "                 et_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"precStd\"]]\n",
    "\n",
    "# Difference variables\n",
    "d_ET_acc = et_classifier[\"Difference\"][\"Accuracy\"]\n",
    "d_ET_f1 = et_classifier[\"Difference\"][\"F1 Score\"]\n",
    "d_ET_rec = et_classifier[\"Difference\"][\"Recall\"]\n",
    "d_ET_prec = et_classifier[\"Difference\"][\"Precision\"]\n",
    "\n",
    "# Output the results\n",
    "print(\"f1_ET_best =\", f1_ET_best)\n",
    "print(\"acc_ET_best =\", acc_ET_best)\n",
    "print(\"rec_ET_best =\", rec_ET_best)\n",
    "print(\"prec_ET_best =\", prec_ET_best)\n",
    "\n",
    "print(\"f1_ET_worst =\", f1_ET_worst)\n",
    "print(\"acc_ET_worst =\", acc_ET_worst)\n",
    "print(\"rec_ET_worst =\", rec_ET_worst)\n",
    "print(\"prec_ET_worst =\", prec_ET_worst)\n",
    "\n",
    "print(\"d_f1 =\", d_ET_f1)\n",
    "print(\"d_acc =\", d_ET_acc)\n",
    "print(\"d_rec =\", d_ET_rec)\n",
    "print(\"d_prec =\", d_ET_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_RF_best = [0.7197034319401785, 0.0177831461270605]\n",
      "acc_RF_best = [0.9883351548488418, 0.0024935776839261716]\n",
      "rec_RF_best = [0.7083895689649256, 0.007522545055841562]\n",
      "prec_RF_best = [0.7730769897378899, 0.08069174604705723]\n",
      "f1_RF_worst = [0.7149427942094987, 0.01837623257999105]\n",
      "acc_RF_worst = [0.9881034171162018, 0.0025360563028352908]\n",
      "rec_RF_worst = [0.7015176718417777, 0.005511922067593151]\n",
      "prec_RF_worst = [0.7674769896601521, 0.08350893227882218]\n",
      "d_f1 = 0.47606377306798064\n",
      "d_acc = 0.023173773264006936\n",
      "d_rec = 0.6871897123147841\n",
      "d_prec = 0.5600000077737755\n"
     ]
    }
   ],
   "source": [
    "RF_classifier = results_RF\n",
    "\n",
    "# Best score variables\n",
    "f1_RF_best = [RF_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"f1Mean\"], \n",
    "              RF_classifier[\"Best score\"][\"Std Scores (Best)\"][\"f1Std\"]]\n",
    "acc_RF_best = [RF_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"accMean\"], \n",
    "               RF_classifier[\"Best score\"][\"Std Scores (Best)\"][\"accStd\"]]\n",
    "rec_RF_best = [RF_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"recMean\"], \n",
    "               RF_classifier[\"Best score\"][\"Std Scores (Best)\"][\"recStd\"]]\n",
    "prec_RF_best = [RF_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"precMean\"], \n",
    "                RF_classifier[\"Best score\"][\"Std Scores (Best)\"][\"precStd\"]]\n",
    "\n",
    "# Worst score variables\n",
    "f1_RF_worst = [RF_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"f1Mean\"], \n",
    "               RF_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"f1Std\"]]\n",
    "acc_RF_worst = [RF_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"accMean\"], \n",
    "                RF_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"accStd\"]]\n",
    "rec_RF_worst = [RF_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"recMean\"], \n",
    "                RF_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"recStd\"]]\n",
    "prec_RF_worst = [RF_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"precMean\"], \n",
    "                 RF_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"precStd\"]]\n",
    "\n",
    "# Difference variables\n",
    "d_RF_acc = RF_classifier[\"Difference\"][\"Accuracy\"]\n",
    "d_RF_f1 = RF_classifier[\"Difference\"][\"F1 Score\"]\n",
    "d_RF_rec = RF_classifier[\"Difference\"][\"Recall\"]\n",
    "d_RF_prec = RF_classifier[\"Difference\"][\"Precision\"]\n",
    "\n",
    "# Output the results\n",
    "print(\"f1_RF_best =\", f1_RF_best)\n",
    "print(\"acc_RF_best =\", acc_RF_best)\n",
    "print(\"rec_RF_best =\", rec_RF_best)\n",
    "print(\"prec_RF_best =\", prec_RF_best)\n",
    "\n",
    "print(\"f1_RF_worst =\", f1_RF_worst)\n",
    "print(\"acc_RF_worst =\", acc_RF_worst)\n",
    "print(\"rec_RF_worst =\", rec_RF_worst)\n",
    "print(\"prec_RF_worst =\", prec_RF_worst)\n",
    "\n",
    "print(\"d_f1 =\", d_RF_f1)\n",
    "print(\"d_acc =\", d_RF_acc)\n",
    "print(\"d_rec =\", d_RF_rec)\n",
    "print(\"d_prec =\", d_RF_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_MLP_best = [0.5385025982201224, 0.010739693831363853]\n",
      "acc_MLP_best = [0.9854193579415126, 0.0024138502891582017]\n",
      "rec_MLP_best = [0.5305862878354152, 0.01164069579366274]\n",
      "prec_MLP_best = [0.6060281025748958, 0.0372076861655445]\n",
      "f1_MLP_worst = [0.5114983481436209, 0.010389177322929473]\n",
      "acc_MLP_worst = [0.9857310347185922, 0.0019387461669609822]\n",
      "rec_MLP_worst = [0.4961080679392261, 0.016661909039079607]\n",
      "prec_MLP_worst = [0.6287420530341901, 0.06827471398103704]\n",
      "d_f1 = 2.7004250076501424\n",
      "d_acc = -0.031167677707966135\n",
      "d_rec = 3.4478219896189044\n",
      "d_prec = -2.271395045929425\n"
     ]
    }
   ],
   "source": [
    "MLP_classifier = results_MLP\n",
    "\n",
    "# Best score variables\n",
    "f1_MLP_best = [MLP_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"f1Mean\"], \n",
    "              MLP_classifier[\"Best score\"][\"Std Scores (Best)\"][\"f1Std\"]]\n",
    "acc_MLP_best = [MLP_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"accMean\"], \n",
    "               MLP_classifier[\"Best score\"][\"Std Scores (Best)\"][\"accStd\"]]\n",
    "rec_MLP_best = [MLP_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"recMean\"], \n",
    "               MLP_classifier[\"Best score\"][\"Std Scores (Best)\"][\"recStd\"]]\n",
    "prec_MLP_best = [MLP_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"precMean\"], \n",
    "                MLP_classifier[\"Best score\"][\"Std Scores (Best)\"][\"precStd\"]]\n",
    "\n",
    "# Worst score variables\n",
    "f1_MLP_worst = [MLP_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"f1Mean\"], \n",
    "               MLP_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"f1Std\"]]\n",
    "acc_MLP_worst = [MLP_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"accMean\"], \n",
    "                MLP_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"accStd\"]]\n",
    "rec_MLP_worst = [MLP_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"recMean\"], \n",
    "                MLP_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"recStd\"]]\n",
    "prec_MLP_worst = [MLP_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"precMean\"], \n",
    "                 MLP_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"precStd\"]]\n",
    "\n",
    "# Difference variables\n",
    "d_MLP_acc = MLP_classifier[\"Difference\"][\"Accuracy\"]\n",
    "d_MLP_f1 = MLP_classifier[\"Difference\"][\"F1 Score\"]\n",
    "d_MLP_rec = MLP_classifier[\"Difference\"][\"Recall\"]\n",
    "d_MLP_prec = MLP_classifier[\"Difference\"][\"Precision\"]\n",
    "\n",
    "# Output the results\n",
    "print(\"f1_MLP_best =\", f1_MLP_best)\n",
    "print(\"acc_MLP_best =\", acc_MLP_best)\n",
    "print(\"rec_MLP_best =\", rec_MLP_best)\n",
    "print(\"prec_MLP_best =\", prec_MLP_best)\n",
    "\n",
    "print(\"f1_MLP_worst =\", f1_MLP_worst)\n",
    "print(\"acc_MLP_worst =\", acc_MLP_worst)\n",
    "print(\"rec_MLP_worst =\", rec_MLP_worst)\n",
    "print(\"prec_MLP_worst =\", prec_MLP_worst)\n",
    "\n",
    "print(\"d_f1 =\", d_MLP_f1)\n",
    "print(\"d_acc =\", d_MLP_acc)\n",
    "print(\"d_rec =\", d_MLP_rec)\n",
    "print(\"d_prec =\", d_MLP_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Macro F1-score     & 72.49 $\\pm$ 0.01   & 71.97 $\\pm$ 0.02  & 53.85 $\\pm$ 0.01 & & 71.75 $\\pm$ 0.02 & 71.49 $\\pm$ 0.02 & 51.15 $\\pm$ 0.01 & & 0.74 & 0.48 & 2.7 \\\n",
      "& Macro Recall       & 71.33 $\\pm$ 0.01  & 70.84 $\\pm$ 0.01 & 53.06 $\\pm$ 0.01 & & 70.8 $\\pm$ 0.0 & 70.15 $\\pm$ 0.01 & 49.61 $\\pm$ 0.02 & & 0.53 & 0.69 & 3.45 \\\n",
      "& Macro Precision    & 76.85 $\\pm$ 0.06   & 77.31 $\\pm$ 0.08 & 60.6 $\\pm$ 0.04 & & 76.24 $\\pm$ 0.08 & 76.75 $\\pm$ 0.08 & 62.87 $\\pm$ 0.07 & & 0.6 & 0.56 & -2.27 \\\n",
      "& Accuracy           & 98.82 $\\pm$ 0.0 & 98.83 $\\pm$ 0.0 & 98.54 $\\pm$ 0.0 & & 98.79 $\\pm$ 0.0 & 98.81 $\\pm$ 0.0 & 98.57 $\\pm$ 0.0 & & 0.02 & 0.02 & -0.03 \\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_table = f\"\"\"\n",
    "Macro F1-score     & {round(f1_ET_best[0]*100, 2)} $\\pm$ {round(f1_ET_best[1], 2)}   & {round(f1_RF_best[0]*100, 2)} $\\pm$ {round(f1_RF_best[1], 2)}  & {round(f1_MLP_best[0]*100, 2)} $\\pm$ {round(f1_MLP_best[1], 2)} & & {round(f1_ET_worst[0]*100, 2)} $\\pm$ {round(f1_ET_worst[1], 2)} & {round(f1_RF_worst[0]*100, 2)} $\\pm$ {round(f1_RF_worst[1], 2)} & {round(f1_MLP_worst[0]*100, 2)} $\\pm$ {round(f1_MLP_worst[1], 2)} & & {round(d_ET_f1, 2)} & {round(d_RF_f1, 2)} & {round(d_MLP_f1, 2)} \\\\\n",
    "& Macro Recall       & {round(rec_ET_best[0]*100, 2)} $\\pm$ {round(rec_ET_best[1], 2)}  & {round(rec_RF_best[0]*100, 2)} $\\pm$ {round(rec_RF_best[1], 2)} & {round(rec_MLP_best[0]*100, 2)} $\\pm$ {round(rec_MLP_best[1], 2)} & & {round(rec_ET_worst[0]*100, 2)} $\\pm$ {round(rec_ET_worst[1], 2)} & {round(rec_RF_worst[0]*100, 2)} $\\pm$ {round(rec_RF_worst[1], 2)} & {round(rec_MLP_worst[0]*100, 2)} $\\pm$ {round(rec_MLP_worst[1], 2)} & & {round(d_ET_rec, 2)} & {round(d_RF_rec, 2)} & {round(d_MLP_rec, 2)} \\\\\n",
    "& Macro Precision    & {round(prec_ET_best[0]*100, 2)} $\\pm$ {round(prec_ET_best[1], 2)}   & {round(prec_RF_best[0]*100, 2)} $\\pm$ {round(prec_RF_best[1], 2)} & {round(prec_MLP_best[0]*100, 2)} $\\pm$ {round(prec_MLP_best[1], 2)} & & {round(prec_ET_worst[0]*100, 2)} $\\pm$ {round(prec_ET_worst[1], 2)} & {round(prec_RF_worst[0]*100, 2)} $\\pm$ {round(prec_RF_worst[1], 2)} & {round(prec_MLP_worst[0]*100, 2)} $\\pm$ {round(prec_MLP_worst[1], 2)} & & {round(d_ET_prec, 2)} & {round(d_RF_prec, 2)} & {round(d_MLP_prec, 2)} \\\\\n",
    "& Accuracy           & {round(acc_ET_best[0]*100, 2)} $\\pm$ {round(acc_ET_best[1], 2)} & {round(acc_RF_best[0]*100, 2)} $\\pm$ {round(acc_RF_best[1], 2)} & {round(acc_MLP_best[0]*100, 2)} $\\pm$ {round(acc_MLP_best[1], 2)} & & {round(acc_ET_worst[0]*100, 2)} $\\pm$ {round(acc_ET_worst[1], 2)} & {round(acc_RF_worst[0]*100, 2)} $\\pm$ {round(acc_RF_worst[1], 2)} & {round(acc_MLP_worst[0]*100, 2)} $\\pm$ {round(acc_MLP_worst[1], 2)} & & {round(d_ET_acc, 2)} & {round(d_RF_acc, 2)} & {round(d_MLP_acc, 2)} \\\\\n",
    "\"\"\"\n",
    "\n",
    "# Output the LaTeX table\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_score(path):\n",
    "    with open(path, 'r') as f:\n",
    "        loaded_results = json.load(f)\n",
    "    return loaded_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ET = load_score('../results/allFeatures/ET_unsw_nfstream_all.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_RF = load_score('../results/allFeatures/RF_unsw_nfstream_all.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_MLP = load_score('../results/allFeatures/MLP_unsw_nfstream_all.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ET classifier: \n",
      " {'Best score': {'Best Timeout': [5, 60], 'Mean Scores (Best)': {'f1Mean': 0.7342473598339057, 'accMean': 0.9876591701291437, 'recMean': 0.7255895439806894, 'precMean': 0.7717838208392581}, 'Std Scores (Best)': {'f1Std': 0.019310698199600705, 'accStd': 0.0032020019005501994, 'recStd': 0.007611444749275763, 'precStd': 0.06729512987901248}}, 'Worst score': {'Worst Timeout': [0.5, 2], 'Mean Scores (Worst)': {'f1Mean': 0.727919352769024, 'accMean': 0.9873979250245188, 'recMean': 0.7163903629104751, 'precMean': 0.7647216536607813}, 'Std Scores (Worst)': {'f1Std': 0.019478274339293247, 'accStd': 0.0032868258338943587, 'recStd': 0.006095144492869859, 'precStd': 0.06558796513187659}}, 'Difference': {'Accuracy': 0.026124510462488537, 'F1 Score': 0.632800706488168, 'Precision': 0.7062167178476852, 'Recall': 0.9199181070214335}}\n",
      "\n",
      "RF classifier :\n",
      " {'Best score': {'Best Timeout': [2, 60], 'Mean Scores (Best)': {'f1Mean': 0.7314977701162555, 'accMean': 0.9877789502128834, 'recMean': 0.7221376252102373, 'precMean': 0.7690021144242354}, 'Std Scores (Best)': {'f1Std': 0.017292482309190765, 'accStd': 0.0030696716065319626, 'recStd': 0.010271826477481587, 'precStd': 0.06400907415298697}}, 'Worst score': {'Worst Timeout': [1, 30], 'Mean Scores (Worst)': {'f1Mean': 0.7272608460925207, 'accMean': 0.9876468698179968, 'recMean': 0.7162335544901789, 'precMean': 0.7672747993108052}, 'Std Scores (Worst)': {'f1Std': 0.01882637169826683, 'accStd': 0.0031456995851551544, 'recStd': 0.0071042466128469674, 'precStd': 0.06529936964371949}}, 'Difference': {'Accuracy': 0.01320803948866578, 'F1 Score': 0.4236924023734767, 'Precision': 0.17273151134301612, 'Recall': 0.5904070720058385}}\n",
      "\n",
      "MLP classifier : \n",
      " {'Best score': {'Best Timeout': [5, 5], 'Mean Scores (Best)': {'f1Mean': 0.6204771832050486, 'accMean': 0.9872118458338679, 'recMean': 0.6006456671675517, 'precMean': 0.6873414554257925}, 'Std Scores (Best)': {'f1Std': 0.01924877118725694, 'accStd': 0.0025144814448416534, 'recStd': 0.011721903571034135, 'precStd': 0.059965698272801404}}, 'Worst score': {'Worst Timeout': [4, 60], 'Mean Scores (Worst)': {'f1Mean': 0.6003694689216568, 'accMean': 0.9862542317406193, 'recMean': 0.5854240547326686, 'precMean': 0.6984860474987927}, 'Std Scores (Worst)': {'f1Std': 0.007479278470207558, 'accStd': 0.0026617060383723663, 'recStd': 0.01922047099897969, 'precStd': 0.05885844133063189}}, 'Difference': {'Accuracy': 0.0957614093248571, 'F1 Score': 2.0107714283391864, 'Precision': -1.1144592073000226, 'Recall': 1.522161243488318}}\n"
     ]
    }
   ],
   "source": [
    "print(\"ET classifier: \\n\" , results_ET)\n",
    "print(\"\\nRF classifier :\\n\" , results_RF)\n",
    "print(\"\\nMLP classifier : \\n\" , results_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_ET_best = [0.7342473598339057, 0.019310698199600705]\n",
      "acc_ET_best = [0.9876591701291437, 0.0032020019005501994]\n",
      "rec_ET_best = [0.7255895439806894, 0.007611444749275763]\n",
      "prec_ET_best = [0.7717838208392581, 0.06729512987901248]\n",
      "f1_ET_worst = [0.727919352769024, 0.019478274339293247]\n",
      "acc_ET_worst = [0.9873979250245188, 0.0032868258338943587]\n",
      "rec_ET_worst = [0.7163903629104751, 0.006095144492869859]\n",
      "prec_ET_worst = [0.7647216536607813, 0.06558796513187659]\n",
      "d_f1 = 0.632800706488168\n",
      "d_acc = 0.026124510462488537\n",
      "d_rec = 0.9199181070214335\n",
      "d_prec = 0.7062167178476852\n"
     ]
    }
   ],
   "source": [
    "et_classifier = results_ET\n",
    "\n",
    "# Best score variables\n",
    "f1_ET_best = [et_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"f1Mean\"], \n",
    "              et_classifier[\"Best score\"][\"Std Scores (Best)\"][\"f1Std\"]]\n",
    "acc_ET_best = [et_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"accMean\"], \n",
    "               et_classifier[\"Best score\"][\"Std Scores (Best)\"][\"accStd\"]]\n",
    "rec_ET_best = [et_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"recMean\"], \n",
    "               et_classifier[\"Best score\"][\"Std Scores (Best)\"][\"recStd\"]]\n",
    "prec_ET_best = [et_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"precMean\"], \n",
    "                et_classifier[\"Best score\"][\"Std Scores (Best)\"][\"precStd\"]]\n",
    "\n",
    "# Worst score variables\n",
    "f1_ET_worst = [et_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"f1Mean\"], \n",
    "               et_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"f1Std\"]]\n",
    "acc_ET_worst = [et_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"accMean\"], \n",
    "                et_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"accStd\"]]\n",
    "rec_ET_worst = [et_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"recMean\"], \n",
    "                et_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"recStd\"]]\n",
    "prec_ET_worst = [et_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"precMean\"], \n",
    "                 et_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"precStd\"]]\n",
    "\n",
    "# Difference variables\n",
    "d_ET_acc = et_classifier[\"Difference\"][\"Accuracy\"]\n",
    "d_ET_f1 = et_classifier[\"Difference\"][\"F1 Score\"]\n",
    "d_ET_rec = et_classifier[\"Difference\"][\"Recall\"]\n",
    "d_ET_prec = et_classifier[\"Difference\"][\"Precision\"]\n",
    "\n",
    "# Output the results\n",
    "print(\"f1_ET_best =\", f1_ET_best)\n",
    "print(\"acc_ET_best =\", acc_ET_best)\n",
    "print(\"rec_ET_best =\", rec_ET_best)\n",
    "print(\"prec_ET_best =\", prec_ET_best)\n",
    "\n",
    "print(\"f1_ET_worst =\", f1_ET_worst)\n",
    "print(\"acc_ET_worst =\", acc_ET_worst)\n",
    "print(\"rec_ET_worst =\", rec_ET_worst)\n",
    "print(\"prec_ET_worst =\", prec_ET_worst)\n",
    "\n",
    "print(\"d_f1 =\", d_ET_f1)\n",
    "print(\"d_acc =\", d_ET_acc)\n",
    "print(\"d_rec =\", d_ET_rec)\n",
    "print(\"d_prec =\", d_ET_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_RF_best = [0.7314977701162555, 0.017292482309190765]\n",
      "acc_RF_best = [0.9877789502128834, 0.0030696716065319626]\n",
      "rec_RF_best = [0.7221376252102373, 0.010271826477481587]\n",
      "prec_RF_best = [0.7690021144242354, 0.06400907415298697]\n",
      "f1_RF_worst = [0.7272608460925207, 0.01882637169826683]\n",
      "acc_RF_worst = [0.9876468698179968, 0.0031456995851551544]\n",
      "rec_RF_worst = [0.7162335544901789, 0.0071042466128469674]\n",
      "prec_RF_worst = [0.7672747993108052, 0.06529936964371949]\n",
      "d_f1 = 0.4236924023734767\n",
      "d_acc = 0.01320803948866578\n",
      "d_rec = 0.5904070720058385\n",
      "d_prec = 0.17273151134301612\n"
     ]
    }
   ],
   "source": [
    "RF_classifier = results_RF\n",
    "\n",
    "# Best score variables\n",
    "f1_RF_best = [RF_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"f1Mean\"], \n",
    "              RF_classifier[\"Best score\"][\"Std Scores (Best)\"][\"f1Std\"]]\n",
    "acc_RF_best = [RF_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"accMean\"], \n",
    "               RF_classifier[\"Best score\"][\"Std Scores (Best)\"][\"accStd\"]]\n",
    "rec_RF_best = [RF_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"recMean\"], \n",
    "               RF_classifier[\"Best score\"][\"Std Scores (Best)\"][\"recStd\"]]\n",
    "prec_RF_best = [RF_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"precMean\"], \n",
    "                RF_classifier[\"Best score\"][\"Std Scores (Best)\"][\"precStd\"]]\n",
    "\n",
    "# Worst score variables\n",
    "f1_RF_worst = [RF_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"f1Mean\"], \n",
    "               RF_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"f1Std\"]]\n",
    "acc_RF_worst = [RF_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"accMean\"], \n",
    "                RF_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"accStd\"]]\n",
    "rec_RF_worst = [RF_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"recMean\"], \n",
    "                RF_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"recStd\"]]\n",
    "prec_RF_worst = [RF_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"precMean\"], \n",
    "                 RF_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"precStd\"]]\n",
    "\n",
    "# Difference variables\n",
    "d_RF_acc = RF_classifier[\"Difference\"][\"Accuracy\"]\n",
    "d_RF_f1 = RF_classifier[\"Difference\"][\"F1 Score\"]\n",
    "d_RF_rec = RF_classifier[\"Difference\"][\"Recall\"]\n",
    "d_RF_prec = RF_classifier[\"Difference\"][\"Precision\"]\n",
    "\n",
    "# Output the results\n",
    "print(\"f1_RF_best =\", f1_RF_best)\n",
    "print(\"acc_RF_best =\", acc_RF_best)\n",
    "print(\"rec_RF_best =\", rec_RF_best)\n",
    "print(\"prec_RF_best =\", prec_RF_best)\n",
    "\n",
    "print(\"f1_RF_worst =\", f1_RF_worst)\n",
    "print(\"acc_RF_worst =\", acc_RF_worst)\n",
    "print(\"rec_RF_worst =\", rec_RF_worst)\n",
    "print(\"prec_RF_worst =\", prec_RF_worst)\n",
    "\n",
    "print(\"d_f1 =\", d_RF_f1)\n",
    "print(\"d_acc =\", d_RF_acc)\n",
    "print(\"d_rec =\", d_RF_rec)\n",
    "print(\"d_prec =\", d_RF_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_MLP_best = [0.6204771832050486, 0.01924877118725694]\n",
      "acc_MLP_best = [0.9872118458338679, 0.0025144814448416534]\n",
      "rec_MLP_best = [0.6006456671675517, 0.011721903571034135]\n",
      "prec_MLP_best = [0.6873414554257925, 0.059965698272801404]\n",
      "f1_MLP_worst = [0.6003694689216568, 0.007479278470207558]\n",
      "acc_MLP_worst = [0.9862542317406193, 0.0026617060383723663]\n",
      "rec_MLP_worst = [0.5854240547326686, 0.01922047099897969]\n",
      "prec_MLP_worst = [0.6984860474987927, 0.05885844133063189]\n",
      "d_f1 = 2.0107714283391864\n",
      "d_acc = 0.0957614093248571\n",
      "d_rec = 1.522161243488318\n",
      "d_prec = -1.1144592073000226\n"
     ]
    }
   ],
   "source": [
    "MLP_classifier = results_MLP\n",
    "\n",
    "# Best score variables\n",
    "f1_MLP_best = [MLP_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"f1Mean\"], \n",
    "              MLP_classifier[\"Best score\"][\"Std Scores (Best)\"][\"f1Std\"]]\n",
    "acc_MLP_best = [MLP_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"accMean\"], \n",
    "               MLP_classifier[\"Best score\"][\"Std Scores (Best)\"][\"accStd\"]]\n",
    "rec_MLP_best = [MLP_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"recMean\"], \n",
    "               MLP_classifier[\"Best score\"][\"Std Scores (Best)\"][\"recStd\"]]\n",
    "prec_MLP_best = [MLP_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"precMean\"], \n",
    "                MLP_classifier[\"Best score\"][\"Std Scores (Best)\"][\"precStd\"]]\n",
    "\n",
    "# Worst score variables\n",
    "f1_MLP_worst = [MLP_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"f1Mean\"], \n",
    "               MLP_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"f1Std\"]]\n",
    "acc_MLP_worst = [MLP_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"accMean\"], \n",
    "                MLP_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"accStd\"]]\n",
    "rec_MLP_worst = [MLP_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"recMean\"], \n",
    "                MLP_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"recStd\"]]\n",
    "prec_MLP_worst = [MLP_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"precMean\"], \n",
    "                 MLP_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"precStd\"]]\n",
    "\n",
    "# Difference variables\n",
    "d_MLP_acc = MLP_classifier[\"Difference\"][\"Accuracy\"]\n",
    "d_MLP_f1 = MLP_classifier[\"Difference\"][\"F1 Score\"]\n",
    "d_MLP_rec = MLP_classifier[\"Difference\"][\"Recall\"]\n",
    "d_MLP_prec = MLP_classifier[\"Difference\"][\"Precision\"]\n",
    "\n",
    "# Output the results\n",
    "print(\"f1_MLP_best =\", f1_MLP_best)\n",
    "print(\"acc_MLP_best =\", acc_MLP_best)\n",
    "print(\"rec_MLP_best =\", rec_MLP_best)\n",
    "print(\"prec_MLP_best =\", prec_MLP_best)\n",
    "\n",
    "print(\"f1_MLP_worst =\", f1_MLP_worst)\n",
    "print(\"acc_MLP_worst =\", acc_MLP_worst)\n",
    "print(\"rec_MLP_worst =\", rec_MLP_worst)\n",
    "print(\"prec_MLP_worst =\", prec_MLP_worst)\n",
    "\n",
    "print(\"d_f1 =\", d_MLP_f1)\n",
    "print(\"d_acc =\", d_MLP_acc)\n",
    "print(\"d_rec =\", d_MLP_rec)\n",
    "print(\"d_prec =\", d_MLP_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Macro F1-score     & 73.42 $\\pm$ 0.02   & 73.15 $\\pm$ 0.02  & 62.05 $\\pm$ 0.02 & & 72.79 $\\pm$ 0.02 & 72.73 $\\pm$ 0.02 & 60.04 $\\pm$ 0.01 & & 0.63 & 0.42 & 2.01 \\\n",
      "& Macro Recall       & 72.56 $\\pm$ 0.01  & 72.21 $\\pm$ 0.01 & 60.06 $\\pm$ 0.01 & & 71.64 $\\pm$ 0.01 & 71.62 $\\pm$ 0.01 & 58.54 $\\pm$ 0.02 & & 0.92 & 0.59 & 1.52 \\\n",
      "& Macro Precision    & 77.18 $\\pm$ 0.07   & 76.9 $\\pm$ 0.06 & 68.73 $\\pm$ 0.06 & & 76.47 $\\pm$ 0.07 & 76.73 $\\pm$ 0.07 & 69.85 $\\pm$ 0.06 & & 0.71 & 0.17 & -1.11 \\\n",
      "& Accuracy           & 98.77 $\\pm$ 0.0 & 98.78 $\\pm$ 0.0 & 98.72 $\\pm$ 0.0 & & 98.74 $\\pm$ 0.0 & 98.76 $\\pm$ 0.0 & 98.63 $\\pm$ 0.0 & & 0.03 & 0.01 & 0.1 \\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_table = f\"\"\"\n",
    "Macro F1-score     & {round(f1_ET_best[0]*100, 2)} $\\pm$ {round(f1_ET_best[1], 2)}   & {round(f1_RF_best[0]*100, 2)} $\\pm$ {round(f1_RF_best[1], 2)}  & {round(f1_MLP_best[0]*100, 2)} $\\pm$ {round(f1_MLP_best[1], 2)} & & {round(f1_ET_worst[0]*100, 2)} $\\pm$ {round(f1_ET_worst[1], 2)} & {round(f1_RF_worst[0]*100, 2)} $\\pm$ {round(f1_RF_worst[1], 2)} & {round(f1_MLP_worst[0]*100, 2)} $\\pm$ {round(f1_MLP_worst[1], 2)} & & {round(d_ET_f1, 2)} & {round(d_RF_f1, 2)} & {round(d_MLP_f1, 2)} \\\\\n",
    "& Macro Recall       & {round(rec_ET_best[0]*100, 2)} $\\pm$ {round(rec_ET_best[1], 2)}  & {round(rec_RF_best[0]*100, 2)} $\\pm$ {round(rec_RF_best[1], 2)} & {round(rec_MLP_best[0]*100, 2)} $\\pm$ {round(rec_MLP_best[1], 2)} & & {round(rec_ET_worst[0]*100, 2)} $\\pm$ {round(rec_ET_worst[1], 2)} & {round(rec_RF_worst[0]*100, 2)} $\\pm$ {round(rec_RF_worst[1], 2)} & {round(rec_MLP_worst[0]*100, 2)} $\\pm$ {round(rec_MLP_worst[1], 2)} & & {round(d_ET_rec, 2)} & {round(d_RF_rec, 2)} & {round(d_MLP_rec, 2)} \\\\\n",
    "& Macro Precision    & {round(prec_ET_best[0]*100, 2)} $\\pm$ {round(prec_ET_best[1], 2)}   & {round(prec_RF_best[0]*100, 2)} $\\pm$ {round(prec_RF_best[1], 2)} & {round(prec_MLP_best[0]*100, 2)} $\\pm$ {round(prec_MLP_best[1], 2)} & & {round(prec_ET_worst[0]*100, 2)} $\\pm$ {round(prec_ET_worst[1], 2)} & {round(prec_RF_worst[0]*100, 2)} $\\pm$ {round(prec_RF_worst[1], 2)} & {round(prec_MLP_worst[0]*100, 2)} $\\pm$ {round(prec_MLP_worst[1], 2)} & & {round(d_ET_prec, 2)} & {round(d_RF_prec, 2)} & {round(d_MLP_prec, 2)} \\\\\n",
    "& Accuracy           & {round(acc_ET_best[0]*100, 2)} $\\pm$ {round(acc_ET_best[1], 2)} & {round(acc_RF_best[0]*100, 2)} $\\pm$ {round(acc_RF_best[1], 2)} & {round(acc_MLP_best[0]*100, 2)} $\\pm$ {round(acc_MLP_best[1], 2)} & & {round(acc_ET_worst[0]*100, 2)} $\\pm$ {round(acc_ET_worst[1], 2)} & {round(acc_RF_worst[0]*100, 2)} $\\pm$ {round(acc_RF_worst[1], 2)} & {round(acc_MLP_worst[0]*100, 2)} $\\pm$ {round(acc_MLP_worst[1], 2)} & & {round(d_ET_acc, 2)} & {round(d_RF_acc, 2)} & {round(d_MLP_acc, 2)} \\\\\n",
    "\"\"\"\n",
    "\n",
    "# Output the LaTeX table\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FedLab",
   "language": "python",
   "name": "fedlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
