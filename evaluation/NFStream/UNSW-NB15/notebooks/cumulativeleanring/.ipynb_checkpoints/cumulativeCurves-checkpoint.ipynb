{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor  \n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cols = [ 'expiration_id', 'protocol', 'src_port', 'dst_port',\n",
    "       'ip_version',   'bidirectional_duration_ms', 'bidirectional_packets',\n",
    "       'bidirectional_bytes', 'src2dst_duration_ms', 'src2dst_packets',\n",
    "       'src2dst_bytes', 'dst2src_duration_ms', 'dst2src_packets', 'dst2src_bytes',\n",
    "       'bidirectional_min_ps', 'bidirectional_mean_ps',\n",
    "       'bidirectional_stddev_ps', 'bidirectional_max_ps',\n",
    "       'src2dst_min_ps', 'src2dst_mean_ps', 'src2dst_stddev_ps',\n",
    "       'src2dst_max_ps', 'dst2src_min_ps', 'dst2src_mean_ps',\n",
    "       'dst2src_stddev_ps', 'dst2src_max_ps', 'bidirectional_min_piat_ms',\n",
    "       'bidirectional_mean_piat_ms', 'bidirectional_stddev_piat_ms',\n",
    "       'bidirectional_max_piat_ms', 'src2dst_min_piat_ms',\n",
    "       'src2dst_mean_piat_ms', 'src2dst_stddev_piat_ms',\n",
    "       'src2dst_max_piat_ms', 'dst2src_min_piat_ms',\n",
    "       'dst2src_mean_piat_ms', 'dst2src_stddev_piat_ms',\n",
    "       'dst2src_max_piat_ms', 'bidirectional_syn_packets', 'bidirectional_ack_packets',\n",
    "       'bidirectional_psh_packets', 'bidirectional_rst_packets',\n",
    "       'bidirectional_fin_packets', 'src2dst_syn_packets', 'src2dst_ack_packets',\n",
    "       'src2dst_psh_packets', 'src2dst_rst_packets',\n",
    "       'src2dst_fin_packets', 'dst2src_syn_packets', 'dst2src_ack_packets',\n",
    "       'dst2src_psh_packets', 'dst2src_rst_packets',\n",
    "       'dst2src_fin_packets','application_name',\n",
    "       'application_category_name', 'application_is_guessed',\n",
    "       'application_confidence', 'content_type', 'udps.num_pkts_up_to_128_bytes',\n",
    "       'udps.num_pkts_128_to_256_bytes', 'udps.num_pkts_256_to_512_bytes',\n",
    "       'udps.num_pkts_512_to_1024_bytes',\n",
    "       'udps.num_pkts_1024_to_1514_bytes', 'udps.min_ttl', 'udps.max_ttl',\n",
    "       'udps.min_ip_pkt_len', 'udps.max_ip_pkt_len', 'udps.src2dst_flags',\n",
    "       'udps.dst2src_flags', 'udps.tcp_flags', 'udps.tcp_win_max_in',\n",
    "       'udps.tcp_win_max_out', 'udps.icmp_type', 'udps.icmp_v4_type',\n",
    "       'udps.dns_query_id', 'udps.dns_query_type', 'udps.dns_ttl_answer',\n",
    "       'udps.ftp_command_ret_code', 'udps.retransmitted_in_packets',\n",
    "       'udps.retransmitted_out_packets', 'udps.retransmitted_in_bytes',\n",
    "       'udps.retransmitted_out_bytes', 'udps.src_to_dst_second_bytes',\n",
    "       'udps.dst_to_src_second_bytes', 'udps.src_to_dst_avg_throughput',\n",
    "       'udps.dst_to_src_avg_throughput', 'udps.src_to_dst_second_bytes2',\n",
    "       'udps.dst_to_src_second_bytes2', 'udps.src_to_dst_avg_throughput2',\n",
    "       'udps.dst_to_src_avg_throughput2', 'udps.tcp_init_ms',\n",
    "       'udps.tcp_synack_ack_ms', 'udps.tcp_half_closed_time_ms',\n",
    "       'udps.num_pkts_after_termination',\n",
    "       'udps.src2dst_first_packet_payload_len',\n",
    "       'udps.dst2src_first_packet_payload_len',\n",
    "       'udps.bidirectional_transport_bytes',\n",
    "       'udps.bidirectional_payload_bytes', 'udps.src2dst_transport_bytes',\n",
    "       'udps.src2dst_payload_bytes', 'udps.dst2src_transport_bytes',\n",
    "       'udps.dst2src_payload_bytes',\n",
    "       'udps.src2dst_most_freq_payload_ratio',\n",
    "       'udps.src2dst_most_freq_payload_len',\n",
    "       'udps.dst2src_most_freq_payload_ratio',\n",
    "       'udps.dst2src_most_freq_payload_len',\n",
    "       'udps.bidirectional_mean_packet_relative_times',\n",
    "       'udps.bidirectional_stddev_packet_relative_times',\n",
    "       'udps.bidirectional_variance_packet_relative_times',\n",
    "       'udps.bidirectional_coeff_of_var_packet_relative_times',\n",
    "       'udps.bidirectional_skew_from_median_packet_relative_times',\n",
    "       'udps.src2dst_mean_packet_relative_times',\n",
    "       'udps.src2dst_stddev_packet_relative_times',\n",
    "       'udps.src2dst_variance_packet_relative_times',\n",
    "       'udps.src2dst_coeff_of_var_packet_relative_times',\n",
    "       'udps.src2dst_skew_from_median_packet_relative_times',\n",
    "       'udps.dst2src_mean_packet_relative_times',\n",
    "       'udps.dst2src_stddev_packet_relative_times',\n",
    "       'udps.dst2src_variance_packet_relative_times',\n",
    "       'udps.dst2src_coeff_of_var_packet_relative_times',\n",
    "       'udps.dst2src_skew_from_median_packet_relative_times',\n",
    "       'udps.min_req_res_time_diff', 'udps.max_req_res_time_diff',\n",
    "       'udps.mean_req_res_time_diff', 'udps.stddev_req_res_time_diff',\n",
    "       'udps.variance_req_res_time_diff',\n",
    "       'udps.coeff_of_var_req_res_time_diff',\n",
    "       'udps.skew_from_median_req_res_time_diff',\n",
    "       'udps.src2dst_small_packet_payload_packets',\n",
    "       'udps.src2dst_small_packet_payload_ratio',\n",
    "       'udps.dst2src_small_packet_payload_packets',\n",
    "       'udps.dst2src_small_packet_payload_ratio',\n",
    "       'udps.sent_recv_packet_ratio',\n",
    "       'udps.bidirectional_ps_first_quartile',\n",
    "       'udps.bidirectional_ps_second_quartile',\n",
    "       'udps.bidirectional_ps_third_quartile',\n",
    "       'udps.bidirectional_ps_median_absoulte_deviation',\n",
    "       'udps.bidirectional_ps_skewness', 'udps.bidirectional_ps_kurtosis',\n",
    "       'udps.bidirectional_piat_first_quartile',\n",
    "       'udps.bidirectional_piat_second_quartile',\n",
    "       'udps.bidirectional_piat_third_quartile',\n",
    "       'udps.bidirectional_piat_median_absoulte_deviation',\n",
    "       'udps.bidirectional_piat_skewness',\n",
    "       'udps.bidirectional_piat_kurtosis',\n",
    "       'udps.median_req_res_time_diff', 'Attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [ 'expiration_id', 'protocol',\n",
    "       'ip_version',   'bidirectional_duration_ms', 'bidirectional_packets',\n",
    "       'bidirectional_bytes', 'src2dst_duration_ms', 'src2dst_packets',\n",
    "       'src2dst_bytes', 'dst2src_duration_ms', 'dst2src_packets', 'dst2src_bytes',\n",
    "       'bidirectional_min_ps', 'bidirectional_mean_ps',\n",
    "       'bidirectional_stddev_ps', 'bidirectional_max_ps',\n",
    "       'src2dst_min_ps', 'src2dst_mean_ps', 'src2dst_stddev_ps',\n",
    "       'src2dst_max_ps', 'dst2src_min_ps', 'dst2src_mean_ps',\n",
    "       'dst2src_stddev_ps', 'dst2src_max_ps', 'bidirectional_min_piat_ms',\n",
    "       'bidirectional_mean_piat_ms', 'bidirectional_stddev_piat_ms',\n",
    "       'bidirectional_max_piat_ms', 'src2dst_min_piat_ms',\n",
    "       'src2dst_mean_piat_ms', 'src2dst_stddev_piat_ms',\n",
    "       'src2dst_max_piat_ms', 'dst2src_min_piat_ms',\n",
    "       'dst2src_mean_piat_ms', 'dst2src_stddev_piat_ms',\n",
    "       'dst2src_max_piat_ms', 'bidirectional_syn_packets', 'bidirectional_ack_packets',\n",
    "       'bidirectional_psh_packets', 'bidirectional_rst_packets',\n",
    "       'bidirectional_fin_packets', 'src2dst_syn_packets', 'src2dst_ack_packets',\n",
    "       'src2dst_psh_packets', 'src2dst_rst_packets',\n",
    "       'src2dst_fin_packets', 'dst2src_syn_packets', 'dst2src_ack_packets',\n",
    "       'dst2src_psh_packets', 'dst2src_rst_packets',\n",
    "       'dst2src_fin_packets','application_name',\n",
    "       'application_category_name', 'application_is_guessed',\n",
    "       'application_confidence', 'content_type', 'Attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def port_feature(port):\n",
    "    if port < 1024:\n",
    "        return 1\n",
    "    elif port < 49152 and port >= 1024:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(df, cols):\n",
    "    \"\"\"\n",
    "    @param df pandas DataFrame\n",
    "    @param cols a list of columns to encode \n",
    "    @return a DataFrame with one-hot encoding\n",
    "    \"\"\"\n",
    "    les = {}\n",
    "    for each in cols:\n",
    "        le_col = LabelEncoder()\n",
    "        df[each] = le_col.fit_transform(df[each])\n",
    "        les[each] = le_col\n",
    "       \n",
    "    return df, les\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(predictions, targets, timeout, save_path= \"results/ET\"):\n",
    "    name_file_pred = 'predictions_idle_' + str(timeout[0]) + \"_active_\" + str(timeout[1]) + \".p\"\n",
    "    name_file_y = 'targets_idle_' + str(timeout[0]) + \"_active_\" + str(timeout[1]) + \".p\"\n",
    "\n",
    "    pickle.dump(predictions, open(os.path.join(save_path, name_file_pred), 'wb') )\n",
    "    pickle.dump(targets, open(os.path.join(save_path, name_file_y), 'wb') )\n",
    "    \n",
    "def load_predictions(timeout, save_path= \"results/ET\"):\n",
    "    name_file_pred = 'predictions_idle_' + str(timeout[0]) + \"_active_\" + str(timeout[1]) + \".p\"\n",
    "    name_file_y = 'targets_idle_' + str(timeout[0]) + \"_active_\" + str(timeout[1]) + \".p\"\n",
    "    \n",
    "    predictions =  pickle.load(open(os.path.join(save_path, name_file_pred), 'rb') )\n",
    "    targets =  pickle.load(open(os.path.join(save_path, name_file_y), 'rb') )\n",
    "    return predictions, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeouts = [(0.5,2), (1, 2), (2,2), (0.5,3), (1,3), (2, 3), (3,3), (0.5,4), (1, 4), (2,4), (3,4), (4,4), (0.5,5), (1,5), (2,5), (3,5), (4,5), (5,5), (0.5, 30), (1, 30), (2,30), (3,30), (4,30), (5,30), (10, 30), (0.5, 60), (1, 60), (2,60), (3,60), (4,60), (5,60), (10, 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../results/ET/unsw-nb15_results_ET.txt', \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    train_idx, test_idx = next(StratifiedKFold(n_splits=3).split(data, data['Attack']))\n",
    "    train, test = data.iloc[train_idx].reset_index(drop=True), data.iloc[test_idx].reset_index(drop=True)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing timeout :  (0.5, 2)\n",
      "------------------ classes :  ['Analysis' 'Backdoors' 'Benign' 'DoS' 'Exploits' 'Fuzzers' 'Generic'\n",
      " 'Reconnaissance' 'Shellcode' 'Worms']\n",
      "Processing timeout :  (1, 2)\n",
      "------------------ classes :  ['Analysis' 'Backdoors' 'Benign' 'DoS' 'Exploits' 'Fuzzers' 'Generic'\n",
      " 'Reconnaissance' 'Shellcode' 'Worms']\n",
      "Processing timeout :  (2, 2)\n",
      "------------------ classes :  ['Analysis' 'Backdoors' 'Benign' 'DoS' 'Exploits' 'Fuzzers' 'Generic'\n",
      " 'Reconnaissance' 'Shellcode' 'Worms']\n",
      "Processing timeout :  (0.5, 3)\n",
      "------------------ classes :  ['Analysis' 'Backdoors' 'Benign' 'DoS' 'Exploits' 'Fuzzers' 'Generic'\n",
      " 'Reconnaissance' 'Shellcode' 'Worms']\n",
      "Processing timeout :  (1, 3)\n",
      "------------------ classes :  ['Analysis' 'Backdoors' 'Benign' 'DoS' 'Exploits' 'Fuzzers' 'Generic'\n",
      " 'Reconnaissance' 'Shellcode' 'Worms']\n",
      "Processing timeout :  (2, 3)\n",
      "------------------ classes :  ['Analysis' 'Backdoors' 'Benign' 'DoS' 'Exploits' 'Fuzzers' 'Generic'\n",
      " 'Reconnaissance' 'Shellcode' 'Worms']\n",
      "Processing timeout :  (3, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5cd9924f4f1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, class_weight='balanced'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"------------------ classes : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "best_report = None\n",
    "best_timeout = None\n",
    "best_pred = None\n",
    "best_y = None\n",
    "for timeout in timeouts:\n",
    "    print(\"Processing timeout : \", timeout)\n",
    "    idle, active = timeout\n",
    "    out_dir = f'/home/meryem.janati/lustre/nlp_team-um6p-st-sccs-id7fz1zvotk/IDS/janati/IDS/project2/extractions/extractions/new_idle_{idle}min_active_{active}min/UNSW-NB15'\n",
    "    df = pd.read_csv(out_dir+\"/UNSW-NB15.csv\")\n",
    "    file.write(\"\\n==========================================================\\n\")\n",
    "    file.write(f\" active: {active} min   idle: {idle} min \\n\")\n",
    "    file.write(str(df.Attack.value_counts()))\n",
    "    file.write(\"\\n*******************************************\\n\")\n",
    "    file.write(str(df.Attack.value_counts() / df.shape[0] * 100))\n",
    "    file.write(\"\\n*******************************************\\n\")\n",
    "    file.write(str(df['bidirectional_duration_ms'].describe()))\n",
    "    file.write(\"\\n*******************************************\\n\")\n",
    "    df = df[~df.Attack.str.contains('direction_flip')]\n",
    "    df = df.sort_values(by=['bidirectional_last_seen_ms']).reset_index(drop=True)\n",
    "    df_new = df[cols]\n",
    "    df_new['application_name'] = df_new['application_name'].apply(lambda x: x.split(\".\")[0])\n",
    "    df_new['content_type'] = df_new['content_type'].fillna(\"unkown/unkown\")\n",
    "    df_new['content_sub_type'] = df_new['content_type'].apply(lambda x: x.split(\"/\")[1])\n",
    "    df_new['content_type'] = df_new['content_type'].apply(lambda x: x.split(\"/\")[0])\n",
    "    #df_new['src_port'] = df_new['src_port'].apply(lambda x: port_feature(x))\n",
    "    #df_new['dst_port'] = df_new['dst_port'].apply(lambda x: port_feature(x))\n",
    "    df_new = df_new.fillna(0)\n",
    "    categ_cols = [\"application_name\", \"application_category_name\", \"content_sub_type\", \"content_type\" ]\n",
    "    df_new, lbl_encoders = encode(df_new,categ_cols)    \n",
    "    train, test = split_data(df_new)\n",
    "    y_train = train['Attack']\n",
    "    X_train = train.drop('Attack', axis=1)\n",
    "    y_test = test['Attack']\n",
    "    X_test = test.drop('Attack', axis=1)\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    clf = ExtraTreesClassifier(n_estimators=100, random_state=42)#, class_weight='balanced'\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print(\"------------------ classes : \", le.classes_,)\n",
    "    exit(0)\n",
    "    report = classification_report(y_test, pred,  target_names=le.classes_, digits=4)\n",
    "    file.write(report)\n",
    "    #save_predictions(y_test, pred, timeout, save_path='results/ET/')\n",
    "    f1 = f1_score(y_true=y_test, y_pred=pred, average='macro')\n",
    "    if f1 > best_f1: \n",
    "        best_timeout = timeout\n",
    "        best_f1 = f1\n",
    "        best_report= report\n",
    "        best_pred=pred\n",
    "        best_y=y_test\n",
    "    file.write(\"==========================================================\\n\\n\")\n",
    "    file.flush()\n",
    "print(\"--------------- DONE ---------------------\")\n",
    "#save_predictions(best_pred, best_y, save_path='results/ET/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing timeout :  (0.5, 2)\n",
      "Processing timeout :  (1, 2)\n",
      "Processing timeout :  (2, 2)\n",
      "Processing timeout :  (0.5, 3)\n",
      "Processing timeout :  (1, 3)\n",
      "Processing timeout :  (2, 3)\n",
      "Processing timeout :  (3, 3)\n",
      "Processing timeout :  (0.5, 4)\n",
      "Processing timeout :  (1, 4)\n",
      "Processing timeout :  (2, 4)\n",
      "Processing timeout :  (3, 4)\n",
      "Processing timeout :  (4, 4)\n",
      "Processing timeout :  (0.5, 5)\n",
      "Processing timeout :  (1, 5)\n",
      "Processing timeout :  (2, 5)\n",
      "Processing timeout :  (3, 5)\n",
      "Processing timeout :  (4, 5)\n",
      "Processing timeout :  (5, 5)\n",
      "Processing timeout :  (0.5, 30)\n",
      "Processing timeout :  (1, 30)\n",
      "Processing timeout :  (2, 30)\n",
      "Processing timeout :  (3, 30)\n",
      "Processing timeout :  (4, 30)\n",
      "Processing timeout :  (5, 30)\n",
      "Processing timeout :  (10, 30)\n",
      "Processing timeout :  (0.5, 60)\n",
      "Processing timeout :  (1, 60)\n",
      "Processing timeout :  (2, 60)\n",
      "Processing timeout :  (3, 60)\n",
      "Processing timeout :  (4, 60)\n",
      "Processing timeout :  (5, 60)\n",
      "Processing timeout :  (10, 60)\n",
      "--------------- DONE ---------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "save_predictions() missing 1 required positional argument: 'timeout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-91f967c4bc33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--------------- DONE ---------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0msave_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'results/ET/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: save_predictions() missing 1 required positional argument: 'timeout'"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "best_report = None\n",
    "best_timeout = None\n",
    "best_pred = None\n",
    "best_y = None\n",
    "for timeout in timeouts:\n",
    "    print(\"Processing timeout : \", timeout)\n",
    "    idle, active = timeout\n",
    "    out_dir = f'/home/meryem.janati/lustre/nlp_team-um6p-st-sccs-id7fz1zvotk/IDS/janati/IDS/project2/extractions/extractions/new_idle_{idle}min_active_{active}min/UNSW-NB15'\n",
    "    df = pd.read_csv(out_dir+\"/UNSW-NB15.csv\")\n",
    "    file.write(\"\\n==========================================================\\n\")\n",
    "    file.write(f\" active: {active} min   idle: {idle} min \\n\")\n",
    "    file.write(str(df.Attack.value_counts()))\n",
    "    file.write(\"\\n*******************************************\\n\")\n",
    "    file.write(str(df.Attack.value_counts() / df.shape[0] * 100))\n",
    "    file.write(\"\\n*******************************************\\n\")\n",
    "    file.write(str(df['bidirectional_duration_ms'].describe()))\n",
    "    file.write(\"\\n*******************************************\\n\")\n",
    "    df = df[~df.Attack.str.contains('direction_flip')]\n",
    "    df = df.sort_values(by=['bidirectional_last_seen_ms']).reset_index(drop=True)\n",
    "    df_new = df[cols]\n",
    "    df_new['application_name'] = df_new['application_name'].apply(lambda x: x.split(\".\")[0])\n",
    "    df_new['content_type'] = df_new['content_type'].fillna(\"unkown/unkown\")\n",
    "    df_new['content_sub_type'] = df_new['content_type'].apply(lambda x: x.split(\"/\")[1])\n",
    "    df_new['content_type'] = df_new['content_type'].apply(lambda x: x.split(\"/\")[0])\n",
    "    #df_new['src_port'] = df_new['src_port'].apply(lambda x: port_feature(x))\n",
    "    #df_new['dst_port'] = df_new['dst_port'].apply(lambda x: port_feature(x))\n",
    "    df_new = df_new.fillna(0)\n",
    "    categ_cols = [\"application_name\", \"application_category_name\", \"content_sub_type\", \"content_type\" ]\n",
    "    df_new, lbl_encoders = encode(df_new,categ_cols)    \n",
    "    train, test = split_data(df_new)\n",
    "    y_train = train['Attack']\n",
    "    X_train = train.drop('Attack', axis=1)\n",
    "    y_test = test['Attack']\n",
    "    X_test = test.drop('Attack', axis=1)\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    clf = ExtraTreesClassifier(n_estimators=100, random_state=42)#, class_weight='balanced'\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    report = classification_report(y_test, pred,  target_names=le.classes_, digits=4)\n",
    "    file.write(report)\n",
    "    save_predictions(y_test, pred, timeout, save_path='results/ET/')\n",
    "    f1 = f1_score(y_true=y_test, y_pred=pred, average='macro')\n",
    "    if f1 > best_f1: \n",
    "        best_timeout = timeout\n",
    "        best_f1 = f1\n",
    "        best_report= report\n",
    "        best_pred=pred\n",
    "        best_y=y_test\n",
    "    file.write(\"==========================================================\\n\\n\")\n",
    "    file.flush()\n",
    "print(\"--------------- DONE ---------------------\")\n",
    "#save_predictions(best_pred, best_y, save_path='results/ET/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"=========================BEST PERFORMANCE===================\\n\")\n",
    "file.write(f'best timeouts {best_timeout}\\n')\n",
    "file.write(f'best F1-macro {best_f1}\\n')\n",
    "file.write(best_report)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best timeouts:  (3, 4)\n",
      "best F1-macro:  0.7394503950533898\n",
      "best report:                  precision    recall  f1-score   support\n",
      "\n",
      "      Analysis     0.4000    0.0196    0.0374       102\n",
      "     Backdoors     0.8700    0.7500    0.8056       116\n",
      "        Benign     0.9937    0.9990    0.9963    662142\n",
      "           DoS     0.7796    0.5476    0.6433      1156\n",
      "      Exploits     0.8586    0.8754    0.8669      7531\n",
      "       Fuzzers     0.8733    0.4322    0.5782      6138\n",
      "       Generic     0.9346    0.8708    0.9016      1215\n",
      "Reconnaissance     0.9183    0.9030    0.9106      3835\n",
      "     Shellcode     0.8343    0.8591    0.8465       504\n",
      "         Worms     0.8696    0.7547    0.8081        53\n",
      "\n",
      "      accuracy                         0.9907    682792\n",
      "     macro avg     0.8332    0.7011    0.7395    682792\n",
      "  weighted avg     0.9900    0.9907    0.9896    682792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"best timeouts: \", best_timeout)\n",
    "print(\"best F1-macro: \", best_f1)\n",
    "print(\"best report: \", best_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_pred\n",
    "y_test = best_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9907\n",
      "\n",
      "Micro Precision: 0.9907\n",
      "Micro Recall: 0.9907\n",
      "Micro F1-score: 0.9907\n",
      "\n",
      "Macro Precision: 0.8332\n",
      "Macro Recall: 0.7011\n",
      "Macro F1-score: 0.7395\n",
      "\n",
      "Weighted Precision: 0.9900\n",
      "Weighted Recall: 0.9907\n",
      "Weighted F1-score: 0.9896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, auc, roc_curve\n",
    "\n",
    "\n",
    "print('\\nAccuracy: {:.4f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print('Micro Precision: {:.4f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.4f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.4f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.4f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "print('Macro Recall: {:.4f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "print('Macro F1-score: {:.4f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.4f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted Recall: {:.4f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted F1-score: {:.4f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "\n",
    "#fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n",
    "#print('AUC: {:.4f}'.format(auc(fpr, tpr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load predictions - Best and Worst case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading timeout :  (0.5, 2)\n",
      "Loading timeout :  (1, 2)\n",
      "Loading timeout :  (2, 2)\n",
      "Loading timeout :  (0.5, 3)\n",
      "Loading timeout :  (1, 3)\n",
      "Loading timeout :  (2, 3)\n",
      "Loading timeout :  (3, 3)\n",
      "Loading timeout :  (0.5, 4)\n",
      "Loading timeout :  (1, 4)\n",
      "Loading timeout :  (2, 4)\n",
      "Loading timeout :  (3, 4)\n",
      "Loading timeout :  (4, 4)\n",
      "Loading timeout :  (0.5, 5)\n",
      "Loading timeout :  (1, 5)\n",
      "Loading timeout :  (2, 5)\n",
      "Loading timeout :  (3, 5)\n",
      "Loading timeout :  (4, 5)\n",
      "Loading timeout :  (5, 5)\n",
      "Loading timeout :  (0.5, 30)\n",
      "Loading timeout :  (1, 30)\n",
      "Loading timeout :  (2, 30)\n",
      "Loading timeout :  (3, 30)\n",
      "Loading timeout :  (4, 30)\n",
      "Loading timeout :  (5, 30)\n",
      "Loading timeout :  (10, 30)\n",
      "Loading timeout :  (0.5, 60)\n",
      "Loading timeout :  (1, 60)\n",
      "Loading timeout :  (2, 60)\n",
      "Loading timeout :  (3, 60)\n",
      "Loading timeout :  (4, 60)\n",
      "Loading timeout :  (5, 60)\n",
      "Loading timeout :  (10, 60)\n",
      "------------------- DONE -------------------\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "best_report = None\n",
    "best_timeout = None\n",
    "best_pred = None\n",
    "best_y = None\n",
    "\n",
    "worst_f1 = 1\n",
    "worst_report = None\n",
    "worst_timeout = None\n",
    "worst_pred = None\n",
    "worst_y = None\n",
    "\n",
    "\n",
    "classes =  ['Analysis', 'Backdoors', 'Benign', 'DoS', 'Exploits', 'Fuzzers', 'Generic', 'Reconnaissance', 'Shellcode', 'Worms']\n",
    "for timeout in timeouts:\n",
    "    print(\"Loading timeout : \", timeout)\n",
    "    idle, active = timeout\n",
    "    pred, y_test = load_predictions(timeout, save_path= \"../results/ET\")\n",
    "    report = classification_report(y_test, pred,  target_names=classes, digits=4)\n",
    "    f1 = f1_score(y_true=y_test, y_pred=pred, average='macro')\n",
    "    if f1 > best_f1: \n",
    "        best_timeout = timeout\n",
    "        best_f1 = f1\n",
    "        best_report= report\n",
    "        best_pred=pred\n",
    "        best_y=y_test\n",
    "        \n",
    "    if f1 <= worst_f1: \n",
    "        worst_timeout = timeout\n",
    "        worst_f1 = f1\n",
    "        worst_report= report\n",
    "        worst_pred=pred\n",
    "        worst_y=y_test\n",
    "    file.write(\"==========================================================\\n\\n\")\n",
    "    file.flush()\n",
    "print(\"------------------- DONE -------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"=========================BEST PERFORMANCE===================\\n\")\n",
    "file.write(f'best timeouts {best_timeout}\\n')\n",
    "file.write(f'best F1-macro {best_f1}\\n')\n",
    "file.write(f'best resport {best_report}\\n')\n",
    "\n",
    "file.write(\"=========================WORST PERFORMANCE===================\\n\")\n",
    "file.write(f'worst timeouts {worst_timeout}\\n')\n",
    "file.write(f'worst F1-macro {worst_f1}\\n')\n",
    "file.write(f'xorst resport {worst_report}\\n')\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best timeouts:  (3, 4)\n",
      "best F1-macro:  0.7394503950533898\n",
      "best report:                  precision    recall  f1-score   support\n",
      "\n",
      "      Analysis     0.0196    0.4000    0.0374         5\n",
      "     Backdoors     0.7500    0.8700    0.8056       100\n",
      "        Benign     0.9990    0.9937    0.9963    665690\n",
      "           DoS     0.5476    0.7796    0.6433       812\n",
      "      Exploits     0.8754    0.8586    0.8669      7679\n",
      "       Fuzzers     0.4322    0.8733    0.5782      3038\n",
      "       Generic     0.8708    0.9346    0.9016      1132\n",
      "Reconnaissance     0.9030    0.9183    0.9106      3771\n",
      "     Shellcode     0.8591    0.8343    0.8465       519\n",
      "         Worms     0.7547    0.8696    0.8081        46\n",
      "\n",
      "      accuracy                         0.9907    682792\n",
      "     macro avg     0.7011    0.8332    0.7395    682792\n",
      "  weighted avg     0.9936    0.9907    0.9918    682792\n",
      "\n",
      "worst timeouts:  (0.5, 60)\n",
      "worst F1-macro:  0.7297928004281716\n",
      "worst report:                  precision    recall  f1-score   support\n",
      "\n",
      "      Analysis     0.0097    0.2500    0.0187         4\n",
      "     Backdoors     0.7500    0.8614    0.8018       101\n",
      "        Benign     0.9990    0.9935    0.9962    665880\n",
      "           DoS     0.5450    0.7702    0.6383       818\n",
      "      Exploits     0.8723    0.8592    0.8657      7647\n",
      "       Fuzzers     0.4204    0.8732    0.5675      2990\n",
      "       Generic     0.8709    0.9281    0.8986      1141\n",
      "Reconnaissance     0.9043    0.9179    0.9111      3778\n",
      "     Shellcode     0.8591    0.8311    0.8449       521\n",
      "         Worms     0.6981    0.8222    0.7551        45\n",
      "\n",
      "      accuracy                         0.9905    682925\n",
      "     macro avg     0.6929    0.8107    0.7298    682925\n",
      "  weighted avg     0.9936    0.9905    0.9917    682925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"best timeouts: \", best_timeout)\n",
    "print(\"best F1-macro: \", best_f1)\n",
    "print(\"best report: \", best_report)\n",
    "\n",
    "print(\"worst timeouts: \", worst_timeout)\n",
    "print(\"worst F1-macro: \", worst_f1)\n",
    "print(\"worst report: \", worst_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9907\n",
      "\n",
      "Micro Precision: 0.9907\n",
      "Micro Recall: 0.9907\n",
      "Micro F1-score: 0.9907\n",
      "\n",
      "Macro Precision: 0.8332\n",
      "Macro Recall: 0.7011\n",
      "Macro F1-score: 0.7395\n",
      "\n",
      "Weighted Precision: 0.9900\n",
      "Weighted Recall: 0.9907\n",
      "Weighted F1-score: 0.9896\n"
     ]
    }
   ],
   "source": [
    "y_pred =  best_y    # Switched because they were switched when saved\n",
    "y_test =  best_pred\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, auc, roc_curve\n",
    "\n",
    "\n",
    "best_accuracy = accuracy_score(y_test, y_pred)\n",
    "best_precision = precision_score(y_test, y_pred, average='macro')\n",
    "best_recall = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print('\\nAccuracy: {:.4f}\\n'.format(best_accuracy))\n",
    "\n",
    "print('Micro Precision: {:.4f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.4f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.4f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.4f}'.format(best_precision))\n",
    "print('Macro Recall: {:.4f}'.format(best_recall))\n",
    "print('Macro F1-score: {:.4f}\\n'.format(best_f1))\n",
    "\n",
    "print('Weighted Precision: {:.4f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted Recall: {:.4f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted F1-score: {:.4f}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9905\n",
      "\n",
      "Micro Precision: 0.9905\n",
      "Micro Recall: 0.9905\n",
      "Micro F1-score: 0.9905\n",
      "\n",
      "Macro Precision: 0.8107\n",
      "Macro Recall: 0.6929\n",
      "Macro F1-score: 0.7298\n",
      "\n",
      "Weighted Precision: 0.9897\n",
      "Weighted Recall: 0.9905\n",
      "Weighted F1-score: 0.9893\n"
     ]
    }
   ],
   "source": [
    "y_pred = worst_y\n",
    "y_test =  worst_pred\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, auc, roc_curve\n",
    "\n",
    "\n",
    "worst_accuracy = accuracy_score(y_test, y_pred)\n",
    "worst_precision = precision_score(y_test, y_pred, average='macro')\n",
    "worst_recall = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print('\\nAccuracy: {:.4f}\\n'.format(worst_accuracy))\n",
    "\n",
    "print('Micro Precision: {:.4f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.4f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.4f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.4f}'.format(worst_precision))\n",
    "print('Macro Recall: {:.4f}'.format(worst_recall))\n",
    "print('Macro F1-score: {:.4f}\\n'.format(worst_f1))\n",
    "\n",
    "print('Weighted Precision: {:.4f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted Recall: {:.4f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted F1-score: {:.4f}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_best_worst = open('../results/ET/unsw-nb15_best&worst.txt', \"w\")\n",
    "\n",
    "file_best_worst.write(f'best timeouts:  {best_timeout}\\n')\n",
    "file_best_worst.write(f'best F1-macro:  {best_f1}\\n')\n",
    "file_best_worst.write(f'best precision:  {best_precision}\\n')\n",
    "file_best_worst.write(f'best recall:  {best_recall}\\n')\n",
    "file_best_worst.write(f'best accuracy:  {best_accuracy}\\n')\n",
    "file_best_worst.write(f'best report:  {best_report}\\n')\n",
    "\n",
    "file_best_worst.write(f'worst timeouts:  {worst_timeout}\\n')\n",
    "file_best_worst.write(f'worst F1-macro:  {worst_f1}\\n')\n",
    "file_best_worst.write(f'worstt precision:  {worst_precision}\\n')\n",
    "file_best_worst.write(f'worst recall:  {worst_recall}\\n')\n",
    "file_best_worst.write(f'worst accuracy:  {worst_accuracy}\\n')\n",
    "file_best_worst.write(f'worst report:  {worst_report}\\n')\n",
    "file_best_worst.flush()\n",
    "file_best_worst.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ids_data",
   "language": "python",
   "name": "ids_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
