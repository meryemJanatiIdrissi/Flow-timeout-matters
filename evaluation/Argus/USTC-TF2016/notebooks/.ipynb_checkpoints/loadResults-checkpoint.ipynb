{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_score(path):\n",
    "    with open(path, 'r') as f:\n",
    "        loaded_results = json.load(f)\n",
    "    return loaded_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/srv/lustre01/project/nlp_team-um6p-st-sccs-id7fz1zvotk/IDS/janati/IDS/timeouts-IDS/Argus/USTC-TF2016/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ET = load_score('../results/ET_ustc_argus.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_RF = load_score('../results/RF_ustc_argus.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_MLP = load_score('../results/MLP_ustc_argus.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ET classifier: \n",
      " {'Best score': {'Best Timeout': 2, 'Mean Scores (Best)': {'f1Mean': 0.8269448608766666, 'accMean': 0.8484226604747416, 'recMean': 0.8132663775200243, 'precMean': 0.8611005120453135}, 'Std Scores (Best)': {'f1Std': 0.02645405879383127, 'accStd': 0.029150324128506978, 'recStd': 0.027163404823584265, 'precStd': 0.02401393886792438}}, 'Worst score': {'Worst Timeout': 5, 'Mean Scores (Worst)': {'f1Mean': 0.8164037116129205, 'accMean': 0.8307177583022758, 'recMean': 0.8007781591320248, 'precMean': 0.8557875079486902}, 'Std Scores (Worst)': {'f1Std': 0.01789441197774053, 'accStd': 0.014740703262423563, 'recStd': 0.01751727703221992, 'precStd': 0.019967027515519455}}, 'Difference': {'Accuracy': 1.7704902172465786, 'F1 Score': 1.0541149263746163, 'Precision': 0.5313004096623275, 'Recall': 1.2488218387999517}}\n",
      "\n",
      "RF classifier :\n",
      " {'Best score': {'Best Timeout': 2, 'Mean Scores (Best)': {'f1Mean': 0.835244284839866, 'accMean': 0.8512225767112994, 'recMean': 0.8224650269329421, 'precMean': 0.8674685219946902}, 'Std Scores (Best)': {'f1Std': 0.023729731748337944, 'accStd': 0.027006963879671667, 'recStd': 0.02435031226220971, 'precStd': 0.022912044107604435}}, 'Worst score': {'Worst Timeout': 5, 'Mean Scores (Worst)': {'f1Mean': 0.8251809561464715, 'accMean': 0.8338636284146912, 'recMean': 0.8096930200989059, 'precMean': 0.8632631115330327}, 'Std Scores (Worst)': {'f1Std': 0.015557204667309798, 'accStd': 0.014641758116376876, 'recStd': 0.014712269377250238, 'precStd': 0.018836664816854535}}, 'Difference': {'Accuracy': 1.7358948296608223, 'F1 Score': 1.0063328693394546, 'Precision': 0.4205410461657455, 'Recall': 1.2772006834036231}}\n",
      "\n",
      "MLP classifier : \n",
      " {'Best score': {'Best Timeout': 2, 'Mean Scores (Best)': {'f1Mean': 0.7517578472240691, 'accMean': 0.810193271824688, 'recMean': 0.7431969575664289, 'precMean': 0.8273034928632788}, 'Std Scores (Best)': {'f1Std': 0.027219561452688733, 'accStd': 0.0265568236061742, 'recStd': 0.02634186421064994, 'precStd': 0.03190359666428208}}, 'Worst score': {'Worst Timeout': 4, 'Mean Scores (Worst)': {'f1Mean': 0.7381765034642862, 'accMean': 0.7890614078511025, 'recMean': 0.7269624370189567, 'precMean': 0.8148751262892293}, 'Std Scores (Worst)': {'f1Std': 0.019341067292653672, 'accStd': 0.023087982643935363, 'recStd': 0.016838417518516332, 'precStd': 0.02114510977695336}}, 'Difference': {'Accuracy': 2.1131863973585574, 'F1 Score': 1.3581343759782927, 'Precision': 1.2428366574049443, 'Recall': 1.6234520547472209}}\n"
     ]
    }
   ],
   "source": [
    "print(\"ET classifier: \\n\" , results_ET)\n",
    "print(\"\\nRF classifier :\\n\" , results_RF)\n",
    "print(\"\\nMLP classifier : \\n\" , results_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_ET_best = [0.8269448608766666, 0.02645405879383127]\n",
      "acc_ET_best = [0.8484226604747416, 0.029150324128506978]\n",
      "rec_ET_best = [0.8132663775200243, 0.027163404823584265]\n",
      "prec_ET_best = [0.8611005120453135, 0.02401393886792438]\n",
      "f1_ET_worst = [0.8164037116129205, 0.01789441197774053]\n",
      "acc_ET_worst = [0.8307177583022758, 0.014740703262423563]\n",
      "rec_ET_worst = [0.8007781591320248, 0.01751727703221992]\n",
      "prec_ET_worst = [0.8557875079486902, 0.019967027515519455]\n",
      "d_f1 = 1.0541149263746163\n",
      "d_acc = 1.7704902172465786\n",
      "d_rec = 1.2488218387999517\n",
      "d_prec = 0.5313004096623275\n"
     ]
    }
   ],
   "source": [
    "et_classifier = results_ET\n",
    "\n",
    "# Best score variables\n",
    "f1_ET_best = [et_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"f1Mean\"], \n",
    "              et_classifier[\"Best score\"][\"Std Scores (Best)\"][\"f1Std\"]]\n",
    "acc_ET_best = [et_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"accMean\"], \n",
    "               et_classifier[\"Best score\"][\"Std Scores (Best)\"][\"accStd\"]]\n",
    "rec_ET_best = [et_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"recMean\"], \n",
    "               et_classifier[\"Best score\"][\"Std Scores (Best)\"][\"recStd\"]]\n",
    "prec_ET_best = [et_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"precMean\"], \n",
    "                et_classifier[\"Best score\"][\"Std Scores (Best)\"][\"precStd\"]]\n",
    "\n",
    "# Worst score variables\n",
    "f1_ET_worst = [et_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"f1Mean\"], \n",
    "               et_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"f1Std\"]]\n",
    "acc_ET_worst = [et_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"accMean\"], \n",
    "                et_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"accStd\"]]\n",
    "rec_ET_worst = [et_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"recMean\"], \n",
    "                et_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"recStd\"]]\n",
    "prec_ET_worst = [et_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"precMean\"], \n",
    "                 et_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"precStd\"]]\n",
    "\n",
    "# Difference variables\n",
    "d_ET_acc = et_classifier[\"Difference\"][\"Accuracy\"]\n",
    "d_ET_f1 = et_classifier[\"Difference\"][\"F1 Score\"]\n",
    "d_ET_rec = et_classifier[\"Difference\"][\"Recall\"]\n",
    "d_ET_prec = et_classifier[\"Difference\"][\"Precision\"]\n",
    "\n",
    "# Output the results\n",
    "print(\"f1_ET_best =\", f1_ET_best)\n",
    "print(\"acc_ET_best =\", acc_ET_best)\n",
    "print(\"rec_ET_best =\", rec_ET_best)\n",
    "print(\"prec_ET_best =\", prec_ET_best)\n",
    "\n",
    "print(\"f1_ET_worst =\", f1_ET_worst)\n",
    "print(\"acc_ET_worst =\", acc_ET_worst)\n",
    "print(\"rec_ET_worst =\", rec_ET_worst)\n",
    "print(\"prec_ET_worst =\", prec_ET_worst)\n",
    "\n",
    "print(\"d_f1 =\", d_ET_f1)\n",
    "print(\"d_acc =\", d_ET_acc)\n",
    "print(\"d_rec =\", d_ET_rec)\n",
    "print(\"d_prec =\", d_ET_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_RF_best = [0.835244284839866, 0.023729731748337944]\n",
      "acc_RF_best = [0.8512225767112994, 0.027006963879671667]\n",
      "rec_RF_best = [0.8224650269329421, 0.02435031226220971]\n",
      "prec_RF_best = [0.8674685219946902, 0.022912044107604435]\n",
      "f1_RF_worst = [0.8251809561464715, 0.015557204667309798]\n",
      "acc_RF_worst = [0.8338636284146912, 0.014641758116376876]\n",
      "rec_RF_worst = [0.8096930200989059, 0.014712269377250238]\n",
      "prec_RF_worst = [0.8632631115330327, 0.018836664816854535]\n",
      "d_f1 = 1.0063328693394546\n",
      "d_acc = 1.7358948296608223\n",
      "d_rec = 1.2772006834036231\n",
      "d_prec = 0.4205410461657455\n"
     ]
    }
   ],
   "source": [
    "RF_classifier = results_RF\n",
    "\n",
    "# Best score variables\n",
    "f1_RF_best = [RF_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"f1Mean\"], \n",
    "              RF_classifier[\"Best score\"][\"Std Scores (Best)\"][\"f1Std\"]]\n",
    "acc_RF_best = [RF_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"accMean\"], \n",
    "               RF_classifier[\"Best score\"][\"Std Scores (Best)\"][\"accStd\"]]\n",
    "rec_RF_best = [RF_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"recMean\"], \n",
    "               RF_classifier[\"Best score\"][\"Std Scores (Best)\"][\"recStd\"]]\n",
    "prec_RF_best = [RF_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"precMean\"], \n",
    "                RF_classifier[\"Best score\"][\"Std Scores (Best)\"][\"precStd\"]]\n",
    "\n",
    "# Worst score variables\n",
    "f1_RF_worst = [RF_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"f1Mean\"], \n",
    "               RF_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"f1Std\"]]\n",
    "acc_RF_worst = [RF_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"accMean\"], \n",
    "                RF_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"accStd\"]]\n",
    "rec_RF_worst = [RF_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"recMean\"], \n",
    "                RF_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"recStd\"]]\n",
    "prec_RF_worst = [RF_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"precMean\"], \n",
    "                 RF_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"precStd\"]]\n",
    "\n",
    "# Difference variables\n",
    "d_RF_acc = RF_classifier[\"Difference\"][\"Accuracy\"]\n",
    "d_RF_f1 = RF_classifier[\"Difference\"][\"F1 Score\"]\n",
    "d_RF_rec = RF_classifier[\"Difference\"][\"Recall\"]\n",
    "d_RF_prec = RF_classifier[\"Difference\"][\"Precision\"]\n",
    "\n",
    "# Output the results\n",
    "print(\"f1_RF_best =\", f1_RF_best)\n",
    "print(\"acc_RF_best =\", acc_RF_best)\n",
    "print(\"rec_RF_best =\", rec_RF_best)\n",
    "print(\"prec_RF_best =\", prec_RF_best)\n",
    "\n",
    "print(\"f1_RF_worst =\", f1_RF_worst)\n",
    "print(\"acc_RF_worst =\", acc_RF_worst)\n",
    "print(\"rec_RF_worst =\", rec_RF_worst)\n",
    "print(\"prec_RF_worst =\", prec_RF_worst)\n",
    "\n",
    "print(\"d_f1 =\", d_RF_f1)\n",
    "print(\"d_acc =\", d_RF_acc)\n",
    "print(\"d_rec =\", d_RF_rec)\n",
    "print(\"d_prec =\", d_RF_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_MLP_best = [0.7517578472240691, 0.027219561452688733]\n",
      "acc_MLP_best = [0.810193271824688, 0.0265568236061742]\n",
      "rec_MLP_best = [0.7431969575664289, 0.02634186421064994]\n",
      "prec_MLP_best = [0.8273034928632788, 0.03190359666428208]\n",
      "f1_MLP_worst = [0.7381765034642862, 0.019341067292653672]\n",
      "acc_MLP_worst = [0.7890614078511025, 0.023087982643935363]\n",
      "rec_MLP_worst = [0.7269624370189567, 0.016838417518516332]\n",
      "prec_MLP_worst = [0.8148751262892293, 0.02114510977695336]\n",
      "d_f1 = 1.3581343759782927\n",
      "d_acc = 2.1131863973585574\n",
      "d_rec = 1.6234520547472209\n",
      "d_prec = 1.2428366574049443\n"
     ]
    }
   ],
   "source": [
    "MLP_classifier = results_MLP\n",
    "\n",
    "# Best score variables\n",
    "f1_MLP_best = [MLP_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"f1Mean\"], \n",
    "              MLP_classifier[\"Best score\"][\"Std Scores (Best)\"][\"f1Std\"]]\n",
    "acc_MLP_best = [MLP_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"accMean\"], \n",
    "               MLP_classifier[\"Best score\"][\"Std Scores (Best)\"][\"accStd\"]]\n",
    "rec_MLP_best = [MLP_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"recMean\"], \n",
    "               MLP_classifier[\"Best score\"][\"Std Scores (Best)\"][\"recStd\"]]\n",
    "prec_MLP_best = [MLP_classifier[\"Best score\"][\"Mean Scores (Best)\"][\"precMean\"], \n",
    "                MLP_classifier[\"Best score\"][\"Std Scores (Best)\"][\"precStd\"]]\n",
    "\n",
    "# Worst score variables\n",
    "f1_MLP_worst = [MLP_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"f1Mean\"], \n",
    "               MLP_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"f1Std\"]]\n",
    "acc_MLP_worst = [MLP_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"accMean\"], \n",
    "                MLP_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"accStd\"]]\n",
    "rec_MLP_worst = [MLP_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"recMean\"], \n",
    "                MLP_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"recStd\"]]\n",
    "prec_MLP_worst = [MLP_classifier[\"Worst score\"][\"Mean Scores (Worst)\"][\"precMean\"], \n",
    "                 MLP_classifier[\"Worst score\"][\"Std Scores (Worst)\"][\"precStd\"]]\n",
    "\n",
    "# Difference variables\n",
    "d_MLP_acc = MLP_classifier[\"Difference\"][\"Accuracy\"]\n",
    "d_MLP_f1 = MLP_classifier[\"Difference\"][\"F1 Score\"]\n",
    "d_MLP_rec = MLP_classifier[\"Difference\"][\"Recall\"]\n",
    "d_MLP_prec = MLP_classifier[\"Difference\"][\"Precision\"]\n",
    "\n",
    "# Output the results\n",
    "print(\"f1_MLP_best =\", f1_MLP_best)\n",
    "print(\"acc_MLP_best =\", acc_MLP_best)\n",
    "print(\"rec_MLP_best =\", rec_MLP_best)\n",
    "print(\"prec_MLP_best =\", prec_MLP_best)\n",
    "\n",
    "print(\"f1_MLP_worst =\", f1_MLP_worst)\n",
    "print(\"acc_MLP_worst =\", acc_MLP_worst)\n",
    "print(\"rec_MLP_worst =\", rec_MLP_worst)\n",
    "print(\"prec_MLP_worst =\", prec_MLP_worst)\n",
    "\n",
    "print(\"d_f1 =\", d_MLP_f1)\n",
    "print(\"d_acc =\", d_MLP_acc)\n",
    "print(\"d_rec =\", d_MLP_rec)\n",
    "print(\"d_prec =\", d_MLP_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Macro F1-score     & 82.69 $\\pm$ 0.03   & 83.52 $\\pm$ 0.02  & 75.18 $\\pm$ 0.03 & & 81.64 $\\pm$ 0.02 & 82.52 $\\pm$ 0.02 & 73.82 $\\pm$ 0.02 & & 1.05 & 1.01 & 1.36 \\\n",
      "& Macro Recall       & 81.33 $\\pm$ 0.03  & 82.25 $\\pm$ 0.02 & 74.32 $\\pm$ 0.03 & & 80.08 $\\pm$ 0.02 & 80.97 $\\pm$ 0.01 & 72.7 $\\pm$ 0.02 & & 1.25 & 1.28 & 1.62 \\\n",
      "& Macro Precision    & 86.11 $\\pm$ 0.02   & 86.75 $\\pm$ 0.02 & 82.73 $\\pm$ 0.03 & & 85.58 $\\pm$ 0.02 & 86.33 $\\pm$ 0.02 & 81.49 $\\pm$ 0.02 & & 0.53 & 0.42 & 1.24 \\\n",
      "& Accuracy           & 84.84 $\\pm$ 0.03 & 85.12 $\\pm$ 0.03 & 81.02 $\\pm$ 0.03 & & 83.07 $\\pm$ 0.01 & 83.39 $\\pm$ 0.01 & 78.91 $\\pm$ 0.02 & & 1.77 & 1.74 & 2.11 \\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_table = f\"\"\"\n",
    "Macro F1-score     & {round(f1_ET_best[0]*100, 2)} $\\pm$ {round(f1_ET_best[1], 2)}   & {round(f1_RF_best[0]*100, 2)} $\\pm$ {round(f1_RF_best[1], 2)}  & {round(f1_MLP_best[0]*100, 2)} $\\pm$ {round(f1_MLP_best[1], 2)} & & {round(f1_ET_worst[0]*100, 2)} $\\pm$ {round(f1_ET_worst[1], 2)} & {round(f1_RF_worst[0]*100, 2)} $\\pm$ {round(f1_RF_worst[1], 2)} & {round(f1_MLP_worst[0]*100, 2)} $\\pm$ {round(f1_MLP_worst[1], 2)} & & {round(d_ET_f1, 2)} & {round(d_RF_f1, 2)} & {round(d_MLP_f1, 2)} \\\\\n",
    "& Macro Recall       & {round(rec_ET_best[0]*100, 2)} $\\pm$ {round(rec_ET_best[1], 2)}  & {round(rec_RF_best[0]*100, 2)} $\\pm$ {round(rec_RF_best[1], 2)} & {round(rec_MLP_best[0]*100, 2)} $\\pm$ {round(rec_MLP_best[1], 2)} & & {round(rec_ET_worst[0]*100, 2)} $\\pm$ {round(rec_ET_worst[1], 2)} & {round(rec_RF_worst[0]*100, 2)} $\\pm$ {round(rec_RF_worst[1], 2)} & {round(rec_MLP_worst[0]*100, 2)} $\\pm$ {round(rec_MLP_worst[1], 2)} & & {round(d_ET_rec, 2)} & {round(d_RF_rec, 2)} & {round(d_MLP_rec, 2)} \\\\\n",
    "& Macro Precision    & {round(prec_ET_best[0]*100, 2)} $\\pm$ {round(prec_ET_best[1], 2)}   & {round(prec_RF_best[0]*100, 2)} $\\pm$ {round(prec_RF_best[1], 2)} & {round(prec_MLP_best[0]*100, 2)} $\\pm$ {round(prec_MLP_best[1], 2)} & & {round(prec_ET_worst[0]*100, 2)} $\\pm$ {round(prec_ET_worst[1], 2)} & {round(prec_RF_worst[0]*100, 2)} $\\pm$ {round(prec_RF_worst[1], 2)} & {round(prec_MLP_worst[0]*100, 2)} $\\pm$ {round(prec_MLP_worst[1], 2)} & & {round(d_ET_prec, 2)} & {round(d_RF_prec, 2)} & {round(d_MLP_prec, 2)} \\\\\n",
    "& Accuracy           & {round(acc_ET_best[0]*100, 2)} $\\pm$ {round(acc_ET_best[1], 2)} & {round(acc_RF_best[0]*100, 2)} $\\pm$ {round(acc_RF_best[1], 2)} & {round(acc_MLP_best[0]*100, 2)} $\\pm$ {round(acc_MLP_best[1], 2)} & & {round(acc_ET_worst[0]*100, 2)} $\\pm$ {round(acc_ET_worst[1], 2)} & {round(acc_RF_worst[0]*100, 2)} $\\pm$ {round(acc_RF_worst[1], 2)} & {round(acc_MLP_worst[0]*100, 2)} $\\pm$ {round(acc_MLP_worst[1], 2)} & & {round(d_ET_acc, 2)} & {round(d_RF_acc, 2)} & {round(d_MLP_acc, 2)} \\\\\n",
    "\"\"\"\n",
    "\n",
    "# Output the LaTeX table\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FedLab",
   "language": "python",
   "name": "fedlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
